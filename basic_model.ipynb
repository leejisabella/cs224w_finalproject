{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "02bb5713",
      "metadata": {
        "id": "02bb5713"
      },
      "source": [
        "Environment and Import Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3fe805ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe805ec",
        "outputId": "4d8b782c-a20d-44af-f7bf-12574616f9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio -q\n",
        "!pip install torch-geometric -q\n",
        "!pip install dgl -q  # generic DGL (CPU/GPU autodetect)\n",
        "!pip install torchmetrics==1.4.0.post0 scikit-learn pandas numpy tqdm geopy haversine -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "901c809e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901c809e",
        "outputId": "e4ec8db8-a5d8-4beb-f151-1e2914d0d035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, json, math, random, gc, time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.utils import to_undirected, coalesce\n",
        "from torch_geometric.nn import HGTConv, SAGEConv\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from haversine import haversine\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED);\n",
        "if DEVICE.type == 'cuda':\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(\"Device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8008a98",
      "metadata": {
        "id": "e8008a98"
      },
      "source": [
        "JSON processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"filter_all_t.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(type(data))\n",
        "print(list(data.keys())[:10] if isinstance(data, dict) else data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWGABdqNS82v",
        "outputId": "906e53f5-26d1-4a8a-f459-26e436b0106a"
      },
      "id": "FWGABdqNS82v",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "['train', 'val', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"filter_all_t.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Loop through each dataset and save separately\n",
        "for split_name, records in data.items():\n",
        "    df = pd.DataFrame(records)\n",
        "    csv_name = f\"{split_name}.csv\"\n",
        "    df.to_csv(csv_name, index=False)\n",
        "    print(f\"✅ Saved {csv_name} with {len(df)} rows.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY42lM0BPZT6",
        "outputId": "9ad2b3f0-9508-4ed1-a72b-65b3dd83e1a3"
      },
      "id": "DY42lM0BPZT6",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved train.csv with 87013 rows.\n",
            "✅ Saved val.csv with 10860 rows.\n",
            "✅ Saved test.csv with 11015 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loader for train/test/val"
      ],
      "metadata": {
        "id": "IOaEdbLAXA_g"
      },
      "id": "IOaEdbLAXA_g"
    },
    {
      "cell_type": "code",
      "source": [
        "!fusermount -u /content/drive\n",
        "!rm -rf /content/drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHUfSvs_XoI0",
        "outputId": "40953e1a-5769-463e-e3b3-84b38656eb41"
      },
      "id": "RHUfSvs_XoI0",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fusermount: failed to unmount /content/drive: Invalid argument\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "79137a93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79137a93",
        "outputId": "309ad92b-3436-4bdd-89f1-b15b58de0937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 108888 rows from 3 files: ['train.csv', 'val.csv', 'test.csv']\n",
            "                business_id                user_id  rating  \\\n",
            "0  60567465d335d0abfb415b26  101074926318992653684       4   \n",
            "1  6050fa9f5b4ccec8d5cae994  117065749986299237881       5   \n",
            "2  604be10877e81aaed3cc9a1e  106700937793048450809       4   \n",
            "3  60411e017cd8bf130362365a  101643045857250355161       5   \n",
            "4  604139dd7cd8bf1303624208  109802745326785766951       4   \n",
            "\n",
            "                                         review_text  \\\n",
            "0  The tang of the tomato sauce is outstanding. A...   \n",
            "1              Chicken and waffles were really good!   \n",
            "2  The appetizer of colossal shrimp was very good...   \n",
            "3  The fish tacos here  omg! The salad was great ...   \n",
            "4  Ribs are great, as are the mac and cheese, fri...   \n",
            "\n",
            "                                                pics  \\\n",
            "0  ['AF1QipM-2IRmvitARbcJr7deWfe5hyVBg_ArPMQSYvq0...   \n",
            "1   ['AF1QipMpfxIZUT_aymQ3qPGO-QgGYzxbtLZGmHufAp2s']   \n",
            "2  ['AF1QipMNnqM5X9sSyZ9pXRZ1jvrURHN9bZhGdzuEXoP8...   \n",
            "3  ['AF1QipM-a6AGGp4Hgk5RD0gY5sDRp5kEfB1hZLvlRkft...   \n",
            "4   ['AF1QipNVys4yq-5w_3EsDdHpSc9ZNb7Nl30Mfb6Y0Gup']   \n",
            "\n",
            "                                     history_reviews  \\\n",
            "0  [['101074926318992653684_6056272797d555cc6fb0d...   \n",
            "1  [['117065749986299237881_605206f8d8c08f462b93e...   \n",
            "2  [['106700937793048450809_6044300b27f39b7b5d1db...   \n",
            "3  [['101643045857250355161_604fbdd099686c10168c9...   \n",
            "4  [['109802745326785766951_60524fa9f09a4ffff042f...   \n",
            "\n",
            "                    item_id  ts  user_lat  user_lon  item_lat  item_lon  \\\n",
            "0  60567465d335d0abfb415b26   0       NaN       NaN       NaN       NaN   \n",
            "1  6050fa9f5b4ccec8d5cae994   1       NaN       NaN       NaN       NaN   \n",
            "2  604be10877e81aaed3cc9a1e   2       NaN       NaN       NaN       NaN   \n",
            "3  60411e017cd8bf130362365a   3       NaN       NaN       NaN       NaN   \n",
            "4  604139dd7cd8bf1303624208   4       NaN       NaN       NaN       NaN   \n",
            "\n",
            "   price categories  split  \n",
            "0    NaN         []  train  \n",
            "1    NaN         []  train  \n",
            "2    NaN         []  train  \n",
            "3    NaN         []  train  \n",
            "4    NaN         []  train   \n",
            " (108888, 15)\n"
          ]
        }
      ],
      "source": [
        "# Loader for train/test/val sets\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Paths to your three CSVs\n",
        "DATA_DIR = \"/content/drive/MyDrive/CS224W/Data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
        "VAL_CSV   = os.path.join(DATA_DIR, \"val.csv\")\n",
        "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
        "\n",
        "MIN_USER_INTERACTIONS = 2\n",
        "MIN_ITEM_INTERACTIONS = 2\n",
        "\n",
        "def _ensure_required_cols(df: pd.DataFrame, split_name: str) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # Map your headings to the schema the pipeline expects\n",
        "    # business_id -> item_id (keep the original column intact for reference)\n",
        "    if \"business_id\" in df.columns and \"item_id\" not in df.columns:\n",
        "        df[\"item_id\"] = df[\"business_id\"].astype(str)\n",
        "\n",
        "    # Ensure user_id is string\n",
        "    if \"user_id\" in df.columns:\n",
        "        df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    else:\n",
        "        raise ValueError(f\"{split_name} is missing 'user_id' column.\")\n",
        "\n",
        "    # Ensure rating exists and is numeric\n",
        "    if \"rating\" not in df.columns:\n",
        "        df[\"rating\"] = 5.0\n",
        "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\").fillna(5.0)\n",
        "\n",
        "    # Timestamp (not present in CSV) — create a stable dummy ts\n",
        "    # Use the row index to create increasing integers (works for sorting)\n",
        "    if \"ts\" not in df.columns:\n",
        "        df[\"ts\"] = np.arange(len(df), dtype=np.int64)\n",
        "\n",
        "    # Placeholders for metadata we don't have yet\n",
        "    for c in [\"user_lat\", \"user_lon\", \"item_lat\", \"item_lon\", \"price\"]:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "\n",
        "    # Categories placeholder (list-like)\n",
        "    if \"categories\" not in df.columns:\n",
        "        df[\"categories\"] = [[] for _ in range(len(df))]\n",
        "\n",
        "    # Tag the split (handy later)\n",
        "    df[\"split\"] = split_name\n",
        "    return df\n",
        "\n",
        "def load_google_restaurants() -> pd.DataFrame:\n",
        "    \"\"\"Loads train/val/test CSVs (with headers: business_id, user_id, rating, review_text, pics, history_reviews),\n",
        "    standardizes to the expected schema, and returns a single combined DataFrame with a 'split' column.\n",
        "    \"\"\"\n",
        "    existing = [p for p in [TRAIN_CSV, VAL_CSV, TEST_CSV] if os.path.exists(p)]\n",
        "    if not existing:\n",
        "        raise FileNotFoundError(\"Couldn't find train.csv, val.csv, or test.csv in DATA_DIR\")\n",
        "\n",
        "    dfs = []\n",
        "    for path in existing:\n",
        "        split_name = os.path.splitext(os.path.basename(path))[0]  # \"train\"/\"val\"/\"test\"\n",
        "        raw = pd.read_csv(path)\n",
        "        std = _ensure_required_cols(raw, split_name)\n",
        "        dfs.append(std)\n",
        "\n",
        "    df_all = pd.concat(dfs, ignore_index=True)\n",
        "    print(f\"Loaded {len(df_all)} rows from {len(dfs)} files: {[os.path.basename(p) for p in existing]}\")\n",
        "    return df_all\n",
        "\n",
        "df = load_google_restaurants()\n",
        "print(df.head(), \"\\n\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter/encode/split and build the graph with train edges"
      ],
      "metadata": {
        "id": "XLWrUESmXN77"
      },
      "id": "XLWrUESmXN77"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fce7adfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fce7adfe",
        "outputId": "caabeef6-e54c-43d7-8e8b-3438905ef0a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After filtering: (96003, 15)\n",
            "num_users=36364, num_items=17946\n",
            "HeteroData(\n",
            "  user={ num_nodes=36364 },\n",
            "  item={\n",
            "    num_nodes=17946,\n",
            "    x=[17946, 3],\n",
            "  },\n",
            "  (user, rates, item)={ edge_index=[2, 76769] },\n",
            "  (item, rev_by, user)={ edge_index=[2, 76769] },\n",
            "  (item, similar, item)={ edge_index=[2, 3652] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.utils import to_undirected, coalesce\n",
        "\n",
        "DEVICE = \"cpu\"  # change to \"cuda\" if you have a GPU\n",
        "\n",
        "# ---------- Filtering ----------\n",
        "def filter_min_interactions(df, umin=MIN_USER_INTERACTIONS, imin=MIN_ITEM_INTERACTIONS):\n",
        "    \"\"\"Filter out users/items globally with < umin/imin interactions.\"\"\"\n",
        "    grouped_u = df.groupby(\"user_id\").size()\n",
        "    keep_users = set(grouped_u[grouped_u >= umin].index)\n",
        "    grouped_i = df.groupby(\"item_id\").size()\n",
        "    keep_items = set(grouped_i[grouped_i >= imin].index)\n",
        "    out = df[df.user_id.isin(keep_users) & df.item_id.isin(keep_items)].copy()\n",
        "    return out\n",
        "\n",
        "df_all = filter_min_interactions(df)\n",
        "print(\"After filtering:\", df_all.shape)\n",
        "\n",
        "# ---------- Global encoding ----------\n",
        "u_enc = LabelEncoder().fit(df_all[\"user_id\"])\n",
        "i_enc = LabelEncoder().fit(df_all[\"item_id\"])\n",
        "\n",
        "def encode_df(subdf: pd.DataFrame) -> pd.DataFrame:\n",
        "    subdf = subdf.copy()\n",
        "    # Only keep rows that survived global filtering\n",
        "    subdf = subdf[subdf[\"user_id\"].isin(u_enc.classes_) & subdf[\"item_id\"].isin(i_enc.classes_)]\n",
        "    subdf[\"u\"] = u_enc.transform(subdf[\"user_id\"])\n",
        "    subdf[\"i\"] = i_enc.transform(subdf[\"item_id\"])\n",
        "    return subdf\n",
        "\n",
        "train_df = encode_df(df_all[df_all[\"split\"] == \"train\"])\n",
        "val_df   = encode_df(df_all[df_all[\"split\"] == \"val\"])\n",
        "test_df  = encode_df(df_all[df_all[\"split\"] == \"test\"])\n",
        "\n",
        "num_users = len(u_enc.classes_)\n",
        "num_items = len(i_enc.classes_)\n",
        "print(f\"num_users={num_users}, num_items={num_items}\")\n",
        "\n",
        "# ---------- Build hetero graph (train edges only) ----------\n",
        "data = HeteroData()\n",
        "data[\"user\"].num_nodes = num_users\n",
        "data[\"item\"].num_nodes = num_items\n",
        "\n",
        "# user-item edges from train\n",
        "ui_src = torch.tensor(train_df[\"u\"].values, dtype=torch.long)\n",
        "ui_dst = torch.tensor(train_df[\"i\"].values, dtype=torch.long)\n",
        "edge_index = torch.stack([ui_src, ui_dst], dim=0)\n",
        "data[\"user\", \"rates\", \"item\"].edge_index = edge_index\n",
        "data[\"item\", \"rev_by\", \"user\"].edge_index = edge_index.flip(0)\n",
        "\n",
        "# ---------- Item features (metadata not yet available) ----------\n",
        "# Keep the expected 3-dim feature shape [item_lat, item_lon, price], all zeros.\n",
        "# This matches downstream code expecting a (num_items, 3) tensor.\n",
        "item_x = torch.zeros((num_items, 3), dtype=torch.float)\n",
        "data[\"item\"].x = item_x\n",
        "\n",
        "# ---------- Item-item edges ----------\n",
        "# Co-review edges from train: connect items co-rated by the same user at least twice.\n",
        "co_counts = {}\n",
        "for u, grp in train_df.groupby(\"u\"):\n",
        "    items = grp[\"i\"].tolist()\n",
        "    for a in items:\n",
        "        for b in items:\n",
        "            if a >= b:\n",
        "                continue\n",
        "            co_counts[(a, b)] = co_counts.get((a, b), 0) + 1\n",
        "\n",
        "pairs = [(a, b) for (a, b), c in co_counts.items() if c >= 2]\n",
        "if len(pairs) > 0:\n",
        "    ii_src = [a for a, b in pairs]\n",
        "    ii_dst = [b for a, b in pairs]\n",
        "    ii_edge = torch.tensor([ii_src, ii_dst], dtype=torch.long)\n",
        "    ii_edge = to_undirected(ii_edge)\n",
        "    data[\"item\", \"similar\", \"item\"].edge_index = coalesce(ii_edge, num_nodes=num_items)\n",
        "else:\n",
        "    # If no pairs meet the threshold, create an empty edge_index\n",
        "    data[\"item\", \"similar\", \"item\"].edge_index = torch.empty((2,0), dtype=torch.long)\n",
        "\n",
        "data = data.to(DEVICE)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a8a45a",
      "metadata": {
        "id": "74a8a45a"
      },
      "source": [
        "Sampling, Metrics, and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b76b218f",
      "metadata": {
        "id": "b76b218f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "\n",
        "# ---------- BPR Sampler ----------\n",
        "def bpr_triplet_sampler(train_df: pd.DataFrame, num_items: int,\n",
        "                        radius_km: Optional[float]=None,\n",
        "                        item_latlon: Optional[List[Tuple[float,float]]]=None,\n",
        "                        user_pos_map: Optional[Dict[int,set]]=None,\n",
        "                        user_home_latlon: Optional[Dict[int,Tuple[float,float]]]=None,\n",
        "                        batch_size: int = 2048):\n",
        "    \"\"\"\n",
        "    Yields batches of (u, pos_i, neg_j) for BPR.\n",
        "    Works even if geographic metadata is missing.\n",
        "    \"\"\"\n",
        "    # Build user -> positive item map\n",
        "    if user_pos_map is None:\n",
        "        user_pos_map = {u: set(g[\"i\"].values.tolist()) for u, g in train_df.groupby(\"u\")}\n",
        "    users = list(user_pos_map.keys())\n",
        "\n",
        "    # Precompute safe item_latlon array if not provided\n",
        "    if item_latlon is None or len(item_latlon) != num_items:\n",
        "        item_latlon = [(np.nan, np.nan)] * num_items\n",
        "\n",
        "    while True:\n",
        "        uu, ii, jj = [], [], []\n",
        "        for _ in range(batch_size):\n",
        "            u = random.choice(users)\n",
        "            pos_i = random.choice(list(user_pos_map[u]))\n",
        "\n",
        "            # Negative sampling\n",
        "            if radius_km is not None and item_latlon is not None:\n",
        "                neg_j = None\n",
        "                # Determine user's location center (home or positive item)\n",
        "                center = None\n",
        "                if user_home_latlon and u in user_home_latlon:\n",
        "                    center = user_home_latlon[u]\n",
        "                else:\n",
        "                    lat_i, lon_i = item_latlon[pos_i]\n",
        "                    if not (math.isnan(lat_i) or math.isnan(lon_i)):\n",
        "                        center = (lat_i, lon_i)\n",
        "\n",
        "                # If we have a center, attempt radius-aware sampling\n",
        "                if center:\n",
        "                    latc, lonc = center\n",
        "                    candidates = [k for k in range(num_items) if k not in user_pos_map[u]]\n",
        "                    random.shuffle(candidates)\n",
        "                    for k in candidates:\n",
        "                        latk, lonk = item_latlon[k]\n",
        "                        # skip if no coordinates\n",
        "                        if math.isnan(latk) or math.isnan(lonk):\n",
        "                            continue\n",
        "                        if haversine((latc, lonc), (latk, lonk)) <= radius_km:\n",
        "                            neg_j = k\n",
        "                            break\n",
        "                # Fallback to uniform negative sampling\n",
        "                if neg_j is None:\n",
        "                    while True:\n",
        "                        k = random.randrange(num_items)\n",
        "                        if k not in user_pos_map[u]:\n",
        "                            neg_j = k\n",
        "                            break\n",
        "            else:\n",
        "                # Uniform negative sampling (without geo info for now)\n",
        "                while True:\n",
        "                    k = random.randrange(num_items)\n",
        "                    if k not in user_pos_map[u]:\n",
        "                        neg_j = k\n",
        "                        break\n",
        "\n",
        "            uu.append(u)\n",
        "            ii.append(pos_i)\n",
        "            jj.append(neg_j)\n",
        "\n",
        "        yield (\n",
        "            torch.tensor(uu, device=DEVICE),\n",
        "            torch.tensor(ii, device=DEVICE),\n",
        "            torch.tensor(jj, device=DEVICE)\n",
        "        )\n",
        "\n",
        "# ---------- Ranking Metrics Helper Functions ----------\n",
        "def recall_at_k(ranked_items, ground_truth, k=10):\n",
        "    hits = sum([1 for x in ranked_items[:k] if x in ground_truth])\n",
        "    return hits / float(min(k, len(ground_truth))) if ground_truth else 0.0\n",
        "\n",
        "def ndcg_at_k(ranked_items, ground_truth, k=10):\n",
        "    dcg = sum([1.0 / math.log2(idx + 2) for idx, it in enumerate(ranked_items[:k]) if it in ground_truth])\n",
        "    idcg = sum([1.0 / math.log2(i + 2) for i in range(min(k, len(ground_truth)))])\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def geo_discount(distance_km, R=5.0):\n",
        "    return math.exp(-distance_km / R)\n",
        "\n",
        "def geo_ndcg_at_k(ranked_items, ground_truth, user_loc, item_latlon, k=10, R=5.0):\n",
        "    dcg = 0.0\n",
        "    for idx, it in enumerate(ranked_items[:k], start=1):\n",
        "        if it in ground_truth:\n",
        "            w = 1.0\n",
        "            if user_loc and not any(np.isnan(user_loc)):\n",
        "                latu, lonu = user_loc\n",
        "                lati, loni = item_latlon[it]\n",
        "                if not math.isnan(lati) and not math.isnan(loni):\n",
        "                    d = haversine((latu, lonu), (lati, loni))\n",
        "                    w = geo_discount(d, R=R)\n",
        "            dcg += w / math.log2(idx + 1)\n",
        "    idcg = sum([1.0 / math.log2(i + 2) for i in range(min(k, len(ground_truth)))])\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr(ranked_items, ground_truth, k=10):\n",
        "    for idx, it in enumerate(ranked_items[:k], start=1):\n",
        "        if it in ground_truth:\n",
        "            return 1.0 / idx\n",
        "    return 0.0\n",
        "\n",
        "def rmse(preds, trues):\n",
        "    return float(np.sqrt(np.mean((np.array(preds) - np.array(trues)) ** 2)))\n",
        "\n",
        "def mae(preds, trues):\n",
        "    return float(np.mean(np.abs(np.array(preds) - np.array(trues))))\n",
        "\n",
        "# ---------- Dataset Helpers ----------\n",
        "# For now, items have dummy coordinates → all NaNs\n",
        "item_latlon = [(float(v[0]), float(v[1])) for v in data[\"item\"].x[:, :2].tolist()]\n",
        "user_home = {}  # optional; keep empty unless you have user locations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51a5158",
      "metadata": {
        "id": "e51a5158"
      },
      "source": [
        "Baseline Model: LightGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "663c9942",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "663c9942",
        "outputId": "58189f40-7a68-4582-b8da-b7e098da9d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGCN] Epoch 01 | Loss = 3.2987\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-161099898.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# ---------- Run Training ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mlightgcn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lightgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-161099898.py\u001b[0m in \u001b[0;36mtrain_lightgcn\u001b[0;34m(epochs, emb_dim, batch_size, lr, reg)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightGCN] Epoch {ep:02d} | Loss = {total/steps:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------- Basic LightGCN implementation ----------\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_dim=64, num_layers=4, alpha=None):\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
        "        self.num_layers = num_layers\n",
        "        self.alpha = alpha if alpha is not None else [1/(num_layers+1)]*(num_layers+1)\n",
        "\n",
        "        # Check if the graph has user-item edges\n",
        "        if (\"user\", \"rates\", \"item\") in data.edge_types:\n",
        "            edge = data[\"user\", \"rates\", \"item\"].edge_index\n",
        "            u, i = edge[0], edge[1]\n",
        "            # compute degrees\n",
        "            deg_u = torch.bincount(u, minlength=num_users).float()\n",
        "            deg_i = torch.bincount(i, minlength=num_items).float()\n",
        "        else:\n",
        "            # if no edges (edge_index empty)\n",
        "            u = torch.tensor([], dtype=torch.long)\n",
        "            i = torch.tensor([], dtype=torch.long)\n",
        "            deg_u = torch.ones(num_users)\n",
        "            deg_i = torch.ones(num_items)\n",
        "\n",
        "        self.pairs = (u.to(DEVICE), i.to(DEVICE), deg_u.to(DEVICE), deg_i.to(DEVICE))\n",
        "\n",
        "    def propagate(self, user_x, item_x):\n",
        "        u, i, deg_u, deg_i = self.pairs\n",
        "        all_user = [user_x]\n",
        "        all_item = [item_x]\n",
        "\n",
        "        for _ in range(self.num_layers):\n",
        "            msg_u = torch.zeros_like(user_x)\n",
        "            msg_i = torch.zeros_like(item_x)\n",
        "\n",
        "            if len(u) > 0:  # only if edges exist\n",
        "                msg_u.index_add_(\n",
        "                    0,\n",
        "                    u,\n",
        "                    item_x[i] / torch.sqrt(deg_u[u].unsqueeze(1) * deg_i[i].unsqueeze(1) + 1e-8),\n",
        "                )\n",
        "                msg_i.index_add_(\n",
        "                    0,\n",
        "                    i,\n",
        "                    user_x[u] / torch.sqrt(deg_i[i].unsqueeze(1) * deg_u[u].unsqueeze(1) + 1e-8),\n",
        "                )\n",
        "\n",
        "            user_x, item_x = msg_u, msg_i\n",
        "            all_user.append(user_x)\n",
        "            all_item.append(item_x)\n",
        "\n",
        "        # Weighted layer-wise average\n",
        "        alpha_tensor = torch.tensor(self.alpha, device=user_x.device).view(-1, 1, 1)\n",
        "        user_out = (alpha_tensor * torch.stack(all_user)).sum(0)\n",
        "        item_out = (alpha_tensor * torch.stack(all_item)).sum(0)\n",
        "        return user_out, item_out\n",
        "\n",
        "    def forward(self):\n",
        "        u0 = self.user_emb.weight\n",
        "        i0 = self.item_emb.weight\n",
        "        return self.propagate(u0, i0)\n",
        "\n",
        "    def score(self, users, items, user_emb=None, item_emb=None):\n",
        "        if user_emb is None or item_emb is None:\n",
        "            user_emb, item_emb = self.forward()\n",
        "        return (user_emb[users] * item_emb[items]).sum(dim=1)\n",
        "\n",
        "\n",
        "# ---------- BPR Loss Function ----------\n",
        "def bpr_loss(pos_scores, neg_scores, reg=None, params: list = []):\n",
        "    loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
        "    if reg:\n",
        "        loss = loss + reg * sum(p.norm(2).pow(2) for p in params) / len(params)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# ---------- Training Loop ----------\n",
        "def train_lightgcn(epochs=5, emb_dim=64, batch_size=2048, lr=1e-3, reg=1e-4):\n",
        "    model = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "    user_pos = {u: set(g[\"i\"].values.tolist()) for u, g in train_df.groupby(\"u\")}\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        steps = max(1, len(train_df) // batch_size)\n",
        "        for step in range(steps):\n",
        "            u, i, j = next(sampler)\n",
        "            user_emb, item_emb = model()\n",
        "            pos = model.score(u, i, user_emb, item_emb)\n",
        "            neg = model.score(u, j, user_emb, item_emb)\n",
        "            loss = bpr_loss(pos, neg, reg, [model.user_emb.weight, model.item_emb.weight])\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.detach().item()\n",
        "        print(f\"[LightGCN] Epoch {ep:02d} | Loss = {total/steps:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ---------- Run Training ----------\n",
        "# lightgcn_model = train_lightgcn(epochs=30, emb_dim=128, batch_size=1024, lr=5e-4, reg=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, copy, torch\n",
        "import numpy as np\n",
        "\n",
        "# ---------- Basic LightGCN implementation (+ early stopping) ----------\n",
        "def train_lightgcn_with_eval(\n",
        "    epochs=30,\n",
        "    eval_every=5,\n",
        "    emb_dim=128,\n",
        "    num_layers=3,\n",
        "    batch_size=1024,\n",
        "    lr=5e-4,\n",
        "    reg=1e-4,\n",
        "    k_list=[5, 10, 20],\n",
        "    early_stop_patience=5,      # epochs without improvement on NDCG@10\n",
        "):\n",
        "    model = LightGCN(num_users, num_items, emb_dim=emb_dim, num_layers=num_layers).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "\n",
        "    history = {\"epoch\": [], \"loss\": [], \"val\": []}\n",
        "    best_metric = -1.0\n",
        "    best_state = copy.deepcopy(model.state_dict())\n",
        "    no_improve = 0\n",
        "\n",
        "    steps_per_epoch = max(1, len(train_df) // batch_size)\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "\n",
        "        for _ in range(steps_per_epoch):\n",
        "            u, i, j = next(sampler)\n",
        "            user_emb, item_emb = model()\n",
        "            pos = model.score(u, i, user_emb, item_emb)\n",
        "            neg = model.score(u, j, user_emb, item_emb)\n",
        "            loss = bpr_loss(pos, neg, reg, [model.user_emb.weight, model.item_emb.weight])\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running += loss.detach().item()   # <- no warning\n",
        "\n",
        "        avg_loss = running / steps_per_epoch\n",
        "        history[\"epoch\"].append(ep)\n",
        "        history[\"loss\"].append(avg_loss)\n",
        "\n",
        "        print(f\"[LightGCN] Epoch {ep:02d} | Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        # ---- periodic validation for early stopping ----\n",
        "        if (ep % eval_every == 0) or (ep == 1) or (ep == epochs):\n",
        "            val_results = evaluate_model(model, train_df, val_df, k_list=k_list)\n",
        "            history[\"val\"].append((ep, val_results))\n",
        "            metric = val_results.get(\"NDCG@10\", 0.0)  # select your key metric\n",
        "\n",
        "            pretty = \" | \".join([f\"{k}:{v:.4f}\" for k, v in val_results.items()])\n",
        "            print(f\"Val @Epoch {ep}: {pretty}\")\n",
        "\n",
        "            # early stopping on the chosen metric\n",
        "            if metric > best_metric + 1e-6:\n",
        "                best_metric = metric\n",
        "                best_state = copy.deepcopy(model.state_dict())\n",
        "                no_improve = 0\n",
        "                print(\"New best model (by NDCG@10).\")\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= early_stop_patience:\n",
        "                    print(f\"Early stopping (no improvement for {early_stop_patience} evals).\")\n",
        "                    break\n",
        "\n",
        "    # load best and report final val/test\n",
        "    model.load_state_dict(best_state)\n",
        "    print(\"\\nLoaded best model (by NDCG@10).\")\n",
        "\n",
        "    val_results  = evaluate_model(model, train_df, val_df,  k_list=k_list)\n",
        "    test_results = evaluate_model(model, train_df, test_df, k_list=k_list)\n",
        "\n",
        "    print(\"\\n✅ Final Validation:\")\n",
        "    for k, v in val_results.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "    print(\"\\n✅ Final Test:\")\n",
        "    for k, v in test_results.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "    return model, {\"history\": history, \"val\": val_results, \"test\": test_results}\n",
        "\n",
        "# ---- Run it ----\n",
        "lightgcn_model, eval_summary = train_lightgcn_with_eval(\n",
        "    epochs=30,            # increase if still improving\n",
        "    eval_every=5,         # validate every 5 epochs\n",
        "    emb_dim=128,          # try 32/64/128\n",
        "    num_layers=3,         # try 2–4\n",
        "    batch_size=1024,      # adjust for memory\n",
        "    lr=5e-4,\n",
        "    reg=1e-4,\n",
        "    k_list=[5, 10, 20],\n",
        "    early_stop_patience=4\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAylDBmpbA9E",
        "outputId": "a8f902f4-370e-4394-9ec8-2d1f24697d04"
      },
      "id": "gAylDBmpbA9E",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGCN] Epoch 01 | Loss = 3.2955\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1609.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 1: Recall@5:0.0002 | NDCG@5:0.0002 | MRR@5:0.0003 | Recall@10:0.0006 | NDCG@10:0.0003 | MRR@10:0.0004 | Recall@20:0.0011 | NDCG@20:0.0005 | MRR@20:0.0005\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 02 | Loss = 2.1546\n",
            "[LightGCN] Epoch 03 | Loss = 1.5223\n",
            "[LightGCN] Epoch 04 | Loss = 1.1664\n",
            "[LightGCN] Epoch 05 | Loss = 0.9640\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1705.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 5: Recall@5:0.0012 | NDCG@5:0.0010 | MRR@5:0.0012 | Recall@10:0.0016 | NDCG@10:0.0011 | MRR@10:0.0013 | Recall@20:0.0021 | NDCG@20:0.0013 | MRR@20:0.0014\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 06 | Loss = 0.8483\n",
            "[LightGCN] Epoch 07 | Loss = 0.7820\n",
            "[LightGCN] Epoch 08 | Loss = 0.7440\n",
            "[LightGCN] Epoch 09 | Loss = 0.7222\n",
            "[LightGCN] Epoch 10 | Loss = 0.7096\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1735.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 10: Recall@5:0.0018 | NDCG@5:0.0019 | MRR@5:0.0022 | Recall@10:0.0018 | NDCG@10:0.0019 | MRR@10:0.0022 | Recall@20:0.0025 | NDCG@20:0.0021 | MRR@20:0.0023\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 11 | Loss = 0.7025\n",
            "[LightGCN] Epoch 12 | Loss = 0.6984\n",
            "[LightGCN] Epoch 13 | Loss = 0.6961\n",
            "[LightGCN] Epoch 14 | Loss = 0.6948\n",
            "[LightGCN] Epoch 15 | Loss = 0.6940\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1695.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 15: Recall@5:0.0021 | NDCG@5:0.0022 | MRR@5:0.0025 | Recall@10:0.0022 | NDCG@10:0.0022 | MRR@10:0.0026 | Recall@20:0.0025 | NDCG@20:0.0023 | MRR@20:0.0026\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 16 | Loss = 0.6936\n",
            "[LightGCN] Epoch 17 | Loss = 0.6934\n",
            "[LightGCN] Epoch 18 | Loss = 0.6933\n",
            "[LightGCN] Epoch 19 | Loss = 0.6932\n",
            "[LightGCN] Epoch 20 | Loss = 0.6932\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:15<00:00, 229.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 20: Recall@5:0.0019 | NDCG@5:0.0020 | MRR@5:0.0022 | Recall@10:0.0021 | NDCG@10:0.0021 | MRR@10:0.0023 | Recall@20:0.0028 | NDCG@20:0.0023 | MRR@20:0.0024\n",
            "[LightGCN] Epoch 21 | Loss = 0.6931\n",
            "[LightGCN] Epoch 22 | Loss = 0.6931\n",
            "[LightGCN] Epoch 23 | Loss = 0.6931\n",
            "[LightGCN] Epoch 24 | Loss = 0.6931\n",
            "[LightGCN] Epoch 25 | Loss = 0.6931\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:52<00:00, 69.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 25: Recall@5:0.0022 | NDCG@5:0.0022 | MRR@5:0.0025 | Recall@10:0.0025 | NDCG@10:0.0023 | MRR@10:0.0026 | Recall@20:0.0045 | NDCG@20:0.0030 | MRR@20:0.0029\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 26 | Loss = 0.6931\n",
            "[LightGCN] Epoch 27 | Loss = 0.6931\n",
            "[LightGCN] Epoch 28 | Loss = 0.6931\n",
            "[LightGCN] Epoch 29 | Loss = 0.6931\n",
            "[LightGCN] Epoch 30 | Loss = 0.6931\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:53<00:00, 67.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val @Epoch 30: Recall@5:0.0022 | NDCG@5:0.0022 | MRR@5:0.0024 | Recall@10:0.0042 | NDCG@10:0.0029 | MRR@10:0.0029 | Recall@20:0.0046 | NDCG@20:0.0031 | MRR@20:0.0030\n",
            "New best model (by NDCG@10).\n",
            "\n",
            "Loaded best model (by NDCG@10).\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:53<00:00, 68.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on 3642 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3642/3642 [00:52<00:00, 68.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Final Validation:\n",
            "  Recall@5: 0.0022\n",
            "  NDCG@5: 0.0022\n",
            "  MRR@5: 0.0024\n",
            "  Recall@10: 0.0042\n",
            "  NDCG@10: 0.0029\n",
            "  MRR@10: 0.0029\n",
            "  Recall@20: 0.0046\n",
            "  NDCG@20: 0.0031\n",
            "  MRR@20: 0.0030\n",
            "\n",
            "✅ Final Test:\n",
            "  Recall@5: 0.0018\n",
            "  NDCG@5: 0.0021\n",
            "  MRR@5: 0.0029\n",
            "  Recall@10: 0.0029\n",
            "  NDCG@10: 0.0025\n",
            "  MRR@10: 0.0033\n",
            "  Recall@20: 0.0038\n",
            "  NDCG@20: 0.0028\n",
            "  MRR@20: 0.0034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------- Eval helpers ----------\n",
        "def evaluate_model(model, train_df, eval_df, k_list=[5, 10, 20]):\n",
        "    \"\"\"\n",
        "    Evaluate a trained LightGCN model using Recall@K, NDCG@K, and MRR@K.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        user_emb, item_emb = model.forward()\n",
        "\n",
        "    # Build user->train_items map to exclude seen items from ranking\n",
        "    train_user_pos = train_df.groupby(\"u\")[\"i\"].apply(set).to_dict()\n",
        "    eval_user_pos = eval_df.groupby(\"u\")[\"i\"].apply(set).to_dict()\n",
        "\n",
        "    recall_scores = {k: [] for k in k_list}\n",
        "    ndcg_scores = {k: [] for k in k_list}\n",
        "    mrr_scores = {k: [] for k in k_list}\n",
        "\n",
        "    print(f\"Evaluating on {len(eval_user_pos)} users...\")\n",
        "    for u, gt_items in tqdm(eval_user_pos.items()):\n",
        "        if len(gt_items) == 0:\n",
        "            continue\n",
        "\n",
        "        # Compute scores for all items\n",
        "        user_vec = user_emb[u].unsqueeze(0)\n",
        "        scores = torch.matmul(user_vec, item_emb.T).squeeze(0)\n",
        "\n",
        "        # Mask out items the user has already interacted with (training set)\n",
        "        seen_items = train_user_pos.get(u, set())\n",
        "        scores[list(seen_items)] = -1e9\n",
        "\n",
        "        # Get top-K recommendations\n",
        "        ranked_items = torch.topk(scores, k=max(k_list)).indices.cpu().numpy().tolist()\n",
        "\n",
        "        # Compute metrics for each K\n",
        "        for k in k_list:\n",
        "            recall_scores[k].append(recall_at_k(ranked_items, gt_items, k))\n",
        "            ndcg_scores[k].append(ndcg_at_k(ranked_items, gt_items, k))\n",
        "            mrr_scores[k].append(mrr(ranked_items, gt_items, k))\n",
        "\n",
        "    # Aggregate metrics\n",
        "    results = {}\n",
        "    for k in k_list:\n",
        "        results[f\"Recall@{k}\"] = np.mean(recall_scores[k]) if recall_scores[k] else 0.0\n",
        "        results[f\"NDCG@{k}\"] = np.mean(ndcg_scores[k]) if ndcg_scores[k] else 0.0\n",
        "        results[f\"MRR@{k}\"] = np.mean(mrr_scores[k]) if mrr_scores[k] else 0.0\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmlusTs7ZkzT",
        "outputId": "2b3ffab3-d0d2-4eae-c449-167d614c3d6c"
      },
      "id": "fmlusTs7ZkzT",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3628/3628 [00:01<00:00, 2680.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on 3642 users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3642/3642 [00:01<00:00, 2612.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Validation Results:\n",
            "  Recall@5: 0.0021\n",
            "  NDCG@5: 0.0020\n",
            "  MRR@5: 0.0020\n",
            "  Recall@10: 0.0024\n",
            "  NDCG@10: 0.0021\n",
            "  MRR@10: 0.0022\n",
            "  Recall@20: 0.0029\n",
            "  NDCG@20: 0.0023\n",
            "  MRR@20: 0.0023\n",
            "\n",
            "✅ Test Results:\n",
            "  Recall@5: 0.0007\n",
            "  NDCG@5: 0.0008\n",
            "  MRR@5: 0.0012\n",
            "  Recall@10: 0.0007\n",
            "  NDCG@10: 0.0008\n",
            "  MRR@10: 0.0012\n",
            "  Recall@20: 0.0019\n",
            "  NDCG@20: 0.0011\n",
            "  MRR@20: 0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Evaluate model ----------\n",
        "val_results = evaluate_model(lightgcn_model, train_df, val_df, k_list=[5, 10, 20])\n",
        "test_results = evaluate_model(lightgcn_model, train_df, test_df, k_list=[5, 10, 20])\n",
        "\n",
        "print(\"\\n✅ Validation Results:\")\n",
        "for k, v in val_results.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Test Results:\")\n",
        "for k, v in test_results.items():\n",
        "    print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "xdG0w0SMZ40k"
      },
      "id": "xdG0w0SMZ40k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "10ae0ee6",
      "metadata": {
        "id": "10ae0ee6"
      },
      "source": [
        "Extension Model 1: LightGCL\n",
        "\n",
        "Elements:\n",
        "1. Contrastive self-supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52be409c",
      "metadata": {
        "id": "52be409c"
      },
      "outputs": [],
      "source": [
        "def build_svd_view(train_df, num_users, num_items, rank=64):\n",
        "    # Sparse user-item matrix\n",
        "    rows = torch.tensor(train_df[\"u\"].values, dtype=torch.long)\n",
        "    cols = torch.tensor(train_df[\"i\"].values, dtype=torch.long)\n",
        "    vals = torch.ones(len(train_df), dtype=torch.float32)\n",
        "    A = torch.sparse_coo_tensor(\n",
        "        indices=torch.stack([rows, cols]), values=vals, size=(num_users, num_items)\n",
        "    ).to_dense()  # for simplicity; if too big, sample or chunk\n",
        "    U, S, Vt = torch.linalg.svd(A, full_matrices=False)\n",
        "    Uk = U[:, :rank] * S[:rank]\n",
        "    Vk = Vt[:rank, :].T * S[:rank]\n",
        "    return Uk.to(DEVICE), Vk.to(DEVICE)\n",
        "\n",
        "def info_nce(z, z_tgt, temperature=0.2):\n",
        "    z = F.normalize(z, dim=1)\n",
        "    z_tgt = F.normalize(z_tgt, dim=1)\n",
        "    logits = z @ z_tgt.T / temperature\n",
        "    labels = torch.arange(z.size(0), device=z.device)\n",
        "    return F.cross_entropy(logits, labels)\n",
        "\n",
        "class LightGCL(nn.Module):\n",
        "    def __init__(self, base: LightGCN, lambda_cl=0.1, svd_rank=64):\n",
        "        super().__init__()\n",
        "        self.base = base\n",
        "        self.lambda_cl = lambda_cl\n",
        "        self.Uk, self.Vk = build_svd_view(train_df, base.num_users, base.num_items, rank=svd_rank)\n",
        "\n",
        "    def training_step(self, batch, opt, reg=1e-4):\n",
        "        u,i,j = batch\n",
        "        user_emb, item_emb = self.base()\n",
        "        pos = self.base.score(u,i,user_emb,item_emb)\n",
        "        neg = self.base.score(u,j,user_emb,item_emb)\n",
        "        loss_bpr = bpr_loss(pos,neg,reg,[self.base.user_emb.weight, self.base.item_emb.weight])\n",
        "        # contrastive loss: align learned embeddings with SVD embeddings\n",
        "        cl_u = info_nce(user_emb, self.Uk)\n",
        "        cl_i = info_nce(item_emb, self.Vk)\n",
        "        loss = loss_bpr + self.lambda_cl*(cl_u + cl_i)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        return float(loss.item())\n",
        "\n",
        "def train_lightgcl(epochs=5, emb_dim=64, batch_size=2048, lr=1e-3, reg=1e-4, lambda_cl=0.1):\n",
        "    base = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    model = LightGCL(base, lambda_cl=lambda_cl, svd_rank=emb_dim).to(DEVICE)\n",
        "    opt = torch.optim.Adam(base.parameters(), lr=lr)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total=0.0\n",
        "        for step in range(max(1, len(train_df)//batch_size)):\n",
        "            u,i,j = next(sampler)\n",
        "            total += model.training_step((u,i,j), opt, reg=reg)\n",
        "        print(f\"[LightGCL] epoch {ep} loss {total/(step+1):.4f}\")\n",
        "    return model\n",
        "\n",
        "lightgcl_model = train_lightgcl(epochs=5, emb_dim=64, lambda_cl=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0d5e11",
      "metadata": {
        "id": "dd0d5e11"
      },
      "source": [
        "Extension Model 2: LightGCL + Geographical Awareness\n",
        "\n",
        "Elements:\n",
        "1. Contrastive self-supervision\n",
        "2. Distance-aware scoring\n",
        "3. Radius-aware negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92e3bc18",
      "metadata": {
        "id": "92e3bc18"
      },
      "outputs": [],
      "source": [
        "class LightGCL_Geo(LightGCL):\n",
        "    def __init__(self, base: LightGCN, beta=0.2, R=5.0, lambda_cl=0.1):\n",
        "        super().__init__(base, lambda_cl=lambda_cl, svd_rank=base.user_emb.embedding_dim)\n",
        "        self.beta = beta\n",
        "        self.R = R\n",
        "\n",
        "    def geo_term(self, users, items, user_home, item_latlon):\n",
        "        vals = []\n",
        "        for u,i in zip(users.tolist(), items.tolist()):\n",
        "            uh = user_home.get(u)\n",
        "            if uh is None:\n",
        "                lati,loni = item_latlon[i]\n",
        "                if math.isnan(lati) or math.isnan(loni):\n",
        "                    vals.append(0.0); continue\n",
        "                uh = (lati,loni)  # weak fallback\n",
        "            lati,loni = item_latlon[i]\n",
        "            if math.isnan(lati) or math.isnan(loni):\n",
        "                vals.append(0.0); continue\n",
        "            d = haversine(uh, (lati,loni))\n",
        "            vals.append(math.exp(-d/self.R))\n",
        "        return torch.tensor(vals, device=DEVICE, dtype=torch.float32)\n",
        "\n",
        "    def training_step(self, batch, opt, reg=1e-4):\n",
        "        u,i,j = batch\n",
        "        user_emb, item_emb = self.base()\n",
        "        pos = self.base.score(u,i,user_emb,item_emb) + self.beta * self.geo_term(u,i,user_home,item_latlon)\n",
        "        neg = self.base.score(u,j,user_emb,item_emb) + self.beta * self.geo_term(u,j,user_home,item_latlon)\n",
        "        loss_bpr = bpr_loss(pos,neg,reg,[self.base.user_emb.weight, self.base.item_emb.weight])\n",
        "        cl_u = info_nce(user_emb, self.Uk)\n",
        "        cl_i = info_nce(item_emb, self.Vk)\n",
        "        loss = loss_bpr + self.lambda_cl*(cl_u + cl_i)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "        return float(loss.item())\n",
        "\n",
        "def train_lightgcl_geo(epochs=5, emb_dim=64, batch_size=2048, lr=1e-3, reg=1e-4, lambda_cl=0.1, beta=0.2, R=5.0):\n",
        "    base = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    model = LightGCL_Geo(base, beta=beta, R=R, lambda_cl=lambda_cl).to(DEVICE)\n",
        "    opt = torch.optim.Adam(base.parameters(), lr=lr)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, radius_km=R,\n",
        "                                  item_latlon=item_latlon, user_pos_map=None,\n",
        "                                  user_home_latlon=user_home, batch_size=batch_size)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total=0.0\n",
        "        for step in range(max(1, len(train_df)//batch_size)):\n",
        "            u,i,j = next(sampler)\n",
        "            total += model.training_step((u,i,j), opt, reg=reg)\n",
        "        print(f\"[LightGCL+Geo] epoch {ep} loss {total/(step+1):.4f}\")\n",
        "    return model\n",
        "\n",
        "lightgcl_geo_model = train_lightgcl_geo(epochs=5, emb_dim=64, beta=0.3, R=5.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94239d6d",
      "metadata": {
        "id": "94239d6d"
      },
      "source": [
        "Comparative Model 1: PinSage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28af8794",
      "metadata": {
        "id": "28af8794"
      },
      "outputs": [],
      "source": [
        "class PinSageItemEncoder(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=64, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_dim, hidden_dim) if in_dim>0 else None\n",
        "        self.layers = nn.ModuleList([\n",
        "            PinSAGEConv(in_channels=hidden_dim, out_channels=hidden_dim, heads=1)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = x\n",
        "        if self.proj is not None:\n",
        "            h = self.proj(h)\n",
        "        for conv in self.layers:\n",
        "            h = conv(h, edge_index)\n",
        "            h = F.relu(h)\n",
        "        return F.normalize(h, dim=1)\n",
        "\n",
        "class PinSageRecommender(nn.Module):\n",
        "    def __init__(self, item_in_dim, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.item_enc = PinSAGEItemEncoder(item_in_dim, hidden_dim=hidden_dim)\n",
        "\n",
        "    def forward(self, item_x, ii_edge):\n",
        "        return self.item_enc(item_x, ii_edge)\n",
        "\n",
        "    def user_repr(self, user_pos_items, item_emb):\n",
        "        # mean pool over positives\n",
        "        return F.normalize(item_emb[user_pos_items].mean(0, keepdim=True), dim=1)\n",
        "\n",
        "def train_pinsage(epochs=5, hidden_dim=64, batch_size=2048, lr=1e-3):\n",
        "    item_x = data['item'].x\n",
        "    ii = data['item','similar','item'].edge_index\n",
        "    model = PinSageRecommender(item_x.size(1), hidden_dim=hidden_dim).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    user_pos_map = {u:set(g[\"i\"].values.tolist()) for u,g in train_df.groupby(\"u\")}\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total = 0.0\n",
        "        for step in range(max(1, len(train_df)//batch_size)):\n",
        "            u, i, j = next(sampler)\n",
        "            item_emb = model(item_x, ii)\n",
        "            u_repr = item_emb[i]  # treat pos item as anchor (approximate)\n",
        "            pos = (u_repr * item_emb[i]).sum(1)\n",
        "            neg = (u_repr * item_emb[j]).sum(1)\n",
        "            loss = -F.logsigmoid(pos - neg).mean()\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            total += float(loss)\n",
        "        print(f\"[PinSage] epoch {ep} loss {total/(step+1):.4f}\")\n",
        "    return model\n",
        "\n",
        "pinsage_model = train_pinsage(epochs=5, hidden_dim=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd05290f",
      "metadata": {
        "id": "fd05290f"
      },
      "source": [
        "Comparative Model 2: LightGCN + HGT\n",
        "\n",
        "Elements:\n",
        "1. Base Model LightGCN\n",
        "2. HGT item representation layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2e9d0f",
      "metadata": {
        "id": "2d2e9d0f"
      },
      "outputs": [],
      "source": [
        "# Build minimal hetero metadata graph for items: (item)-[has_cat]->(cat), (item)-[has_price]->(price_level)\n",
        "# From df categories/price\n",
        "cat_encoder = LabelEncoder()\n",
        "all_cats = []\n",
        "for row in df[\"categories\"]:\n",
        "    if isinstance(row, list):\n",
        "        all_cats += row\n",
        "    elif pd.notna(row):\n",
        "        all_cats.append(str(row))\n",
        "if len(all_cats)==0:\n",
        "    all_cats = [\"unknown\"]\n",
        "cat_encoder.fit(list(set(all_cats)))\n",
        "num_cats = len(cat_encoder.classes_)\n",
        "price_levels = sorted(list(set([int(p) if pd.notna(p) else 0 for p in df[\"price\"]])))\n",
        "price_to_idx = {p:i for i,p in enumerate(price_levels)}\n",
        "num_prices = len(price_levels)\n",
        "\n",
        "meta = HeteroData()\n",
        "meta[\"item\"].num_nodes = num_items\n",
        "meta[\"cat\"].num_nodes = num_cats\n",
        "meta[\"price\"].num_nodes = num_prices\n",
        "# item->cat edges\n",
        "src, dst = [], []\n",
        "for i, g in df.groupby(\"i\"):\n",
        "    cats = g[\"categories\"].iloc[0]\n",
        "    if isinstance(cats, list) and len(cats)>0:\n",
        "        for c in cats[:3]:\n",
        "            src.append(i); dst.append(cat_encoder.transform([c])[0])\n",
        "    else:\n",
        "        src.append(i); dst.append(cat_encoder.transform([cat_encoder.classes_[0]])[0])\n",
        "meta[\"item\",\"has_cat\",\"cat\"].edge_index = torch.tensor([src,dst], dtype=torch.long)\n",
        "# item->price edges\n",
        "src, dst = [], []\n",
        "for i, g in df.groupby(\"i\"):\n",
        "    p = g[\"price\"].iloc[0]\n",
        "    p = int(p) if pd.notna(p) else 0\n",
        "    src.append(i); dst.append(price_to_idx.get(p, 0))\n",
        "meta[\"item\",\"has_price\",\"price\"].edge_index = torch.tensor([src,dst], dtype=torch.long)\n",
        "meta = meta.to(DEVICE)\n",
        "\n",
        "class HGTItemEncoder(nn.Module):\n",
        "    def __init__(self, hidden=64, heads=2, layers=2):\n",
        "        super().__init__()\n",
        "        self.emb = nn.ModuleDict({\n",
        "            'item': nn.Embedding(num_items, hidden),\n",
        "            'cat': nn.Embedding(num_cats, hidden),\n",
        "            'price': nn.Embedding(num_prices, hidden),\n",
        "        })\n",
        "        for k in self.emb:\n",
        "            nn.init.xavier_uniform_(self.emb[k].weight)\n",
        "        self.layers = nn.ModuleList([\n",
        "            HGTConv(hidden_channels=hidden, out_channels=hidden, num_types=3, num_relations=2, heads=heads)\n",
        "            for _ in range(layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, meta: HeteroData):\n",
        "        x_dict = {k: self.emb[k].weight for k in ['item','cat','price']}\n",
        "        for conv in self.layers:\n",
        "            x_dict = conv(x_dict, meta.edge_index_dict)\n",
        "            x_dict = {k: F.relu(v) for k,v in x_dict.items()}\n",
        "        return x_dict['item']\n",
        "\n",
        "class LightGCN_HGT(nn.Module):\n",
        "    def __init__(self, lightgcn: LightGCN, hgt_hidden=64):\n",
        "        super().__init__()\n",
        "        self.lgcn = lightgcn\n",
        "        self.hgt = HGTItemEncoder(hidden=hgt_hidden)\n",
        "        self.fuse = nn.Linear(self.lgcn.user_emb.embedding_dim + hgt_hidden, self.lgcn.user_emb.embedding_dim)\n",
        "\n",
        "    def fused_item_emb(self):\n",
        "        user_e, item_e = self.lgcn()\n",
        "        hgt_item = self.hgt(meta)\n",
        "        item_fused = self.fuse(torch.cat([item_e, hgt_item], dim=1))\n",
        "        return user_e, item_fused\n",
        "\n",
        "    def score(self, users, items):\n",
        "        ue, ie = self.fused_item_emb()\n",
        "        return (ue[users]*ie[items]).sum(1)\n",
        "\n",
        "def train_lightgcn_hgt(epochs=5, emb_dim=64, batch_size=2048, lr=1e-3, reg=1e-4):\n",
        "    base = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    model = LightGCN_HGT(base, hgt_hidden=emb_dim).to(DEVICE)\n",
        "    params = list(model.lgcn.parameters()) + list(model.hgt.parameters()) + list(model.fuse.parameters())\n",
        "    opt = torch.optim.Adam(params, lr=lr)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total=0.0\n",
        "        for step in range(max(1, len(train_df)//batch_size)):\n",
        "            u,i,j = next(sampler)\n",
        "            ue, ie = model.lgcn()\n",
        "            hgt_item = model.hgt(meta)\n",
        "            fused = model.fuse(torch.cat([ie, hgt_item], dim=1))\n",
        "            pos = (ue[u]*fused[i]).sum(1)\n",
        "            neg = (ue[u]*fused[j]).sum(1)\n",
        "            loss = bpr_loss(pos,neg,reg, params)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            total += float(loss)\n",
        "        print(f\"[LightGCN+HGT] epoch {ep} loss {total/(step+1):.4f}\")\n",
        "    return model\n",
        "\n",
        "lghgt_model = train_lightgcn_hgt(epochs=5, emb_dim=64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6266ac98",
      "metadata": {
        "id": "6266ac98"
      },
      "source": [
        "Evaluation Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300782ec",
      "metadata": {
        "id": "300782ec"
      },
      "outputs": [],
      "source": [
        "def full_ranking_scores(model, model_name, K_list=(5,10), geo_R=5.0, geo_beta=0.0):\n",
        "    # prepare user->train positives and heldouts\n",
        "    train_pos = {u:set(g[\"i\"].values.tolist()) for u,g in train_df.groupby(\"u\")}\n",
        "    gt_val = {u:set(g[\"i\"].values.tolist()) for u,g in val_df.groupby(\"u\")}\n",
        "    gt_test = {u:set(g[\"i\"].values.tolist()) for u,g in test_df.groupby(\"u\")}\n",
        "    # compute item/user embeddings or scorers per model\n",
        "    with torch.no_grad():\n",
        "        if isinstance(model, LightGCN):\n",
        "            ue, ie = model()\n",
        "            def score_u(u):\n",
        "                # mask train positives for ranking\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u,[]):\n",
        "                    s[it] = -1e9\n",
        "                return s\n",
        "        elif isinstance(model, LightGCL) and not isinstance(model, LightGCL_Geo):\n",
        "            ue, ie = model.base()\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u,[]): s[it] = -1e9\n",
        "                return s\n",
        "        elif isinstance(model, LightGCL_Geo):\n",
        "            ue, ie = model.base()\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                # add geo distance term\n",
        "                geo = []\n",
        "                for it in range(num_items):\n",
        "                    uh = user_home.get(u)\n",
        "                    lati,loni = item_latlon[it]\n",
        "                    w = 0.0\n",
        "                    if uh and not any(np.isnan(uh)) and not math.isnan(lati) and not math.isnan(loni):\n",
        "                        d = haversine(uh,(lati,loni))\n",
        "                        w = math.exp(-d/model.R)\n",
        "                    geo.append(w)\n",
        "                s = s + model.beta*torch.tensor(geo, device=DEVICE)\n",
        "                for it in train_pos.get(u,[]): s[it] = -1e9\n",
        "                return s\n",
        "        elif isinstance(model, PinSageRecommender):\n",
        "            item_x = data['item'].x\n",
        "            ii = data['item','similar','item'].edge_index\n",
        "            item_emb = model(item_x, ii)\n",
        "            def score_u(u):\n",
        "                pos = list(train_pos.get(u, [])) or [0]\n",
        "                uvec = item_emb[pos].mean(0, keepdim=True)\n",
        "                s = (uvec * item_emb).sum(1)\n",
        "                for it in train_pos.get(u,[]): s[it] = -1e9\n",
        "                return s\n",
        "        elif isinstance(model, LightGCN_HGT):\n",
        "            def score_u(u):\n",
        "                ue, ie = model.fused_item_emb()\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u,[]): s[it] = -1e9\n",
        "                return s\n",
        "        else:\n",
        "            raise ValueError(\"Unknown model for evaluation\")\n",
        "\n",
        "        def evaluate(gt_dict, tag):\n",
        "            rec, ndcg, gndcg, rr = [], [], [], []\n",
        "            for u in gt_dict.keys():\n",
        "                s = score_u(u)\n",
        "                ranked = torch.topk(s, k=min(100, num_items)).indices.tolist()\n",
        "                truth = gt_dict[u]\n",
        "                rec.append(recall_at_k(ranked, truth, k=max(K_list)))\n",
        "                ndcg.append(ndcg_at_k(ranked, truth, k=max(K_list)))\n",
        "                # geo-aware NDCG\n",
        "                u_loc = user_home.get(u)\n",
        "                gndcg.append(geo_ndcg_at_k(ranked, truth, u_loc, item_latlon, k=max(K_list), R=geo_R))\n",
        "                rr.append(mrr(ranked, truth, k=max(K_list)))\n",
        "            return np.mean(rec), np.mean(ndcg), np.mean(gndcg), np.mean(rr)\n",
        "\n",
        "        val_scores = evaluate(gt_val, \"val\")\n",
        "        test_scores = evaluate(gt_test, \"test\")\n",
        "        print(f\"[{model_name}] Val  Recall@K:{val_scores[0]:.4f}  NDCG@K:{val_scores[1]:.4f}  GeoNDCG@K:{val_scores[2]:.4f}  MRR:{val_scores[3]:.4f}\")\n",
        "        print(f\"[{model_name}] Test Recall@K:{test_scores[0]:.4f}  NDCG@K:{test_scores[1]:.4f}  GeoNDCG@K:{test_scores[2]:.4f}  MRR:{test_scores[3]:.4f}\")\n",
        "        return {\"model\": model_name, \"val_recall\":val_scores[0], \"val_ndcg\":val_scores[1], \"val_geondcg\":val_scores[2], \"val_mrr\":val_scores[3],\n",
        "                \"test_recall\":test_scores[0], \"test_ndcg\":test_scores[1], \"test_geondcg\":test_scores[2], \"test_mrr\":test_scores[3]}\n",
        "\n",
        "results = []\n",
        "results.append(full_ranking_scores(lightgcn_model, \"LightGCN\"))\n",
        "results.append(full_ranking_scores(lightgcl_model.base, \"LightGCL (base view)\"))\n",
        "results.append(full_ranking_scores(lightgcl_geo_model.base, \"LightGCL+Geo (inference uses geo)\", geo_R=5.0))\n",
        "results.append(full_ranking_scores(pinsage_model, \"PinSage\"))\n",
        "results.append(full_ranking_scores(lghgt_model.lgcn, \"LightGCN+HGT (fused)\"))\n",
        "pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cecca63",
      "metadata": {
        "id": "8cecca63"
      },
      "source": [
        "Rating Metrics (RMSE/MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8838d9a2",
      "metadata": {
        "id": "8838d9a2"
      },
      "outputs": [],
      "source": [
        "def pointwise_eval(model, which=\"val\"):\n",
        "    df_eval = val_df if which==\"val\" else test_df\n",
        "    preds, trues = [], []\n",
        "    with torch.no_grad():\n",
        "        if isinstance(model, LightGCN):\n",
        "            ue, ie = model()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                preds.append(float((ue[r.u] * ie[r.i]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "        elif isinstance(model, LightGCL):\n",
        "            ue, ie = model.base()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                s = float((ue[r.u]*ie[r.i]).sum().item())\n",
        "                preds.append(s); trues.append(float(r.rating))\n",
        "        elif isinstance(model, LightGCL_Geo):\n",
        "            ue, ie = model.base()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                s = float((ue[r.u]*ie[r.i]).sum().item())\n",
        "                # add geo term\n",
        "                uh = user_home.get(int(r.u))\n",
        "                lati,loni = item_latlon[int(r.i)]\n",
        "                if uh and not any(np.isnan(uh)) and not math.isnan(lati) and not math.isnan(loni):\n",
        "                    d = haversine(uh,(lati,loni))\n",
        "                    s += model.beta*math.exp(-d/model.R)\n",
        "                preds.append(s); trues.append(float(r.rating))\n",
        "        elif isinstance(model, PinSageRecommender):\n",
        "            item_x = data['item'].x\n",
        "            ii = data['item','similar','item'].edge_index\n",
        "            item_emb = model(item_x, ii)\n",
        "            for _, r in df_eval.iterrows():\n",
        "                # approximate user vector by mean of their train items\n",
        "                pos = train_df[train_df.u==r.u][\"i\"].values\n",
        "                if len(pos)==0: continue\n",
        "                uvec = item_emb[pos].mean(0)\n",
        "                preds.append(float((uvec * item_emb[r.i]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "        elif isinstance(model, LightGCN_HGT):\n",
        "            ue, ie = model.fused_item_emb()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                preds.append(float((ue[r.u]*ie[r.i]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "        else:\n",
        "            raise ValueError(\"unknown model\")\n",
        "    return {\"rmse\": rmse(preds,trues), \"mae\": mae(preds,trues), \"n\": len(trues)}\n",
        "\n",
        "for name, mdl in [\n",
        "    (\"LightGCN\", lightgcn_model),\n",
        "    (\"LightGCL\", lightgcl_model),\n",
        "    (\"LightGCL+Geo\", lightgcl_geo_model),\n",
        "    (\"PinSage\", pinsage_model),\n",
        "    (\"LightGCN+HGT\", lghgt_model),\n",
        "]:\n",
        "    pe = pointwise_eval(mdl, \"test\")\n",
        "    print(f\"{name} rating RMSE={pe['rmse']:.4f} MAE={pe['mae']:.4f} (n={pe['n']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1b4ae7",
      "metadata": {
        "id": "3d1b4ae7"
      },
      "source": [
        "Vistualization: Comparison Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8bc962c",
      "metadata": {
        "id": "b8bc962c"
      },
      "outputs": [],
      "source": [
        "summary = pd.DataFrame(results).assign(\n",
        "    rmse=[pointwise_eval(m, 'test')[\"rmse\"] for m in [lightgcn_model, lightgcl_model, lightgcl_geo_model, pinsage_model, lghgt_model]],\n",
        "    mae =[pointwise_eval(m, 'test')[\"mae\"]  for m in [lightgcn_model, lightgcl_model, lightgcl_geo_model, pinsage_model, lghgt_model]],\n",
        ")\n",
        "summary = summary[[\"model\",\"test_recall\",\"test_ndcg\",\"test_geondcg\",\"test_mrr\",\"rmse\",\"mae\"]]\n",
        "summary.sort_values(\"test_ndcg\", ascending=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}