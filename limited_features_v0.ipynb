{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "02bb5713",
      "metadata": {
        "id": "02bb5713"
      },
      "source": [
        "Environment and Import Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3fe805ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe805ec",
        "outputId": "4d8b782c-a20d-44af-f7bf-12574616f9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio -q\n",
        "!pip install torch-geometric -q\n",
        "!pip install dgl -q  # generic DGL (CPU/GPU autodetect)\n",
        "!pip install torchmetrics==1.4.0.post0 scikit-learn pandas numpy tqdm geopy haversine -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "901c809e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901c809e",
        "outputId": "e4ec8db8-a5d8-4beb-f151-1e2914d0d035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, json, math, random, gc, time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.utils import to_undirected, coalesce\n",
        "from torch_geometric.nn import HGTConv, SAGEConv\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from haversine import haversine\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED);\n",
        "if DEVICE.type == 'cuda':\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(\"Device:\", DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8008a98",
      "metadata": {
        "id": "e8008a98"
      },
      "source": [
        "JSON processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "FWGABdqNS82v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWGABdqNS82v",
        "outputId": "906e53f5-26d1-4a8a-f459-26e436b0106a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "['train', 'val', 'test']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"filter_all_t.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(type(data))\n",
        "print(list(data.keys())[:10] if isinstance(data, dict) else data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "DY42lM0BPZT6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY42lM0BPZT6",
        "outputId": "9ad2b3f0-9508-4ed1-a72b-65b3dd83e1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved train.csv with 87013 rows.\n",
            "✅ Saved val.csv with 10860 rows.\n",
            "✅ Saved test.csv with 11015 rows.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"filter_all_t.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Loop through each dataset and save separately\n",
        "for split_name, records in data.items():\n",
        "    df = pd.DataFrame(records)\n",
        "    csv_name = f\"{split_name}.csv\"\n",
        "    df.to_csv(csv_name, index=False)\n",
        "    print(f\"✅ Saved {csv_name} with {len(df)} rows.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IOaEdbLAXA_g",
      "metadata": {
        "id": "IOaEdbLAXA_g"
      },
      "source": [
        "Data loader for train/test/val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "RHUfSvs_XoI0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHUfSvs_XoI0",
        "outputId": "40953e1a-5769-463e-e3b3-84b38656eb41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fusermount: failed to unmount /content/drive: Invalid argument\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!fusermount -u /content/drive\n",
        "!rm -rf /content/drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "79137a93",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79137a93",
        "outputId": "309ad92b-3436-4bdd-89f1-b15b58de0937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 108888 rows from 3 files: ['train.csv', 'val.csv', 'test.csv']\n",
            "                business_id                user_id  rating  \\\n",
            "0  60567465d335d0abfb415b26  101074926318992653684       4   \n",
            "1  6050fa9f5b4ccec8d5cae994  117065749986299237881       5   \n",
            "2  604be10877e81aaed3cc9a1e  106700937793048450809       4   \n",
            "3  60411e017cd8bf130362365a  101643045857250355161       5   \n",
            "4  604139dd7cd8bf1303624208  109802745326785766951       4   \n",
            "\n",
            "                                         review_text  \\\n",
            "0  The tang of the tomato sauce is outstanding. A...   \n",
            "1              Chicken and waffles were really good!   \n",
            "2  The appetizer of colossal shrimp was very good...   \n",
            "3  The fish tacos here  omg! The salad was great ...   \n",
            "4  Ribs are great, as are the mac and cheese, fri...   \n",
            "\n",
            "                                                pics  \\\n",
            "0  ['AF1QipM-2IRmvitARbcJr7deWfe5hyVBg_ArPMQSYvq0...   \n",
            "1   ['AF1QipMpfxIZUT_aymQ3qPGO-QgGYzxbtLZGmHufAp2s']   \n",
            "2  ['AF1QipMNnqM5X9sSyZ9pXRZ1jvrURHN9bZhGdzuEXoP8...   \n",
            "3  ['AF1QipM-a6AGGp4Hgk5RD0gY5sDRp5kEfB1hZLvlRkft...   \n",
            "4   ['AF1QipNVys4yq-5w_3EsDdHpSc9ZNb7Nl30Mfb6Y0Gup']   \n",
            "\n",
            "                                     history_reviews  \\\n",
            "0  [['101074926318992653684_6056272797d555cc6fb0d...   \n",
            "1  [['117065749986299237881_605206f8d8c08f462b93e...   \n",
            "2  [['106700937793048450809_6044300b27f39b7b5d1db...   \n",
            "3  [['101643045857250355161_604fbdd099686c10168c9...   \n",
            "4  [['109802745326785766951_60524fa9f09a4ffff042f...   \n",
            "\n",
            "                    item_id  ts  user_lat  user_lon  item_lat  item_lon  \\\n",
            "0  60567465d335d0abfb415b26   0       NaN       NaN       NaN       NaN   \n",
            "1  6050fa9f5b4ccec8d5cae994   1       NaN       NaN       NaN       NaN   \n",
            "2  604be10877e81aaed3cc9a1e   2       NaN       NaN       NaN       NaN   \n",
            "3  60411e017cd8bf130362365a   3       NaN       NaN       NaN       NaN   \n",
            "4  604139dd7cd8bf1303624208   4       NaN       NaN       NaN       NaN   \n",
            "\n",
            "   price categories  split  \n",
            "0    NaN         []  train  \n",
            "1    NaN         []  train  \n",
            "2    NaN         []  train  \n",
            "3    NaN         []  train  \n",
            "4    NaN         []  train   \n",
            " (108888, 15)\n"
          ]
        }
      ],
      "source": [
        "# Loader for train/test/val sets\n",
        "\n",
        "import os, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Paths to your three CSVs\n",
        "DATA_DIR = \"/content/drive/MyDrive/CS224W/Data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n",
        "VAL_CSV   = os.path.join(DATA_DIR, \"val.csv\")\n",
        "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n",
        "\n",
        "MIN_USER_INTERACTIONS = 2\n",
        "MIN_ITEM_INTERACTIONS = 2\n",
        "\n",
        "def _ensure_required_cols(df: pd.DataFrame, split_name: str) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "\n",
        "    # Map your headings to the schema the pipeline expects\n",
        "    # business_id -> item_id (keep the original column intact for reference)\n",
        "    if \"business_id\" in df.columns and \"item_id\" not in df.columns:\n",
        "        df[\"item_id\"] = df[\"business_id\"].astype(str)\n",
        "\n",
        "    # Ensure user_id is string\n",
        "    if \"user_id\" in df.columns:\n",
        "        df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
        "    else:\n",
        "        raise ValueError(f\"{split_name} is missing 'user_id' column.\")\n",
        "\n",
        "    # Ensure rating exists and is numeric\n",
        "    if \"rating\" not in df.columns:\n",
        "        df[\"rating\"] = 5.0\n",
        "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\").fillna(5.0)\n",
        "\n",
        "    # Timestamp (not present in CSV) — create a stable dummy ts\n",
        "    # Use the row index to create increasing integers (works for sorting)\n",
        "    if \"ts\" not in df.columns:\n",
        "        df[\"ts\"] = np.arange(len(df), dtype=np.int64)\n",
        "\n",
        "    # Placeholders for metadata we don't have yet\n",
        "    for c in [\"user_lat\", \"user_lon\", \"item_lat\", \"item_lon\", \"price\"]:\n",
        "        if c not in df.columns:\n",
        "            df[c] = np.nan\n",
        "\n",
        "    # Categories placeholder (list-like)\n",
        "    if \"categories\" not in df.columns:\n",
        "        df[\"categories\"] = [[] for _ in range(len(df))]\n",
        "\n",
        "    # Tag the split (handy later)\n",
        "    df[\"split\"] = split_name\n",
        "    return df\n",
        "\n",
        "def load_google_restaurants() -> pd.DataFrame:\n",
        "    \"\"\"Loads train/val/test CSVs (with headers: business_id, user_id, rating, review_text, pics, history_reviews),\n",
        "    standardizes to the expected schema, and returns a single combined DataFrame with a 'split' column.\n",
        "    \"\"\"\n",
        "    existing = [p for p in [TRAIN_CSV, VAL_CSV, TEST_CSV] if os.path.exists(p)]\n",
        "    if not existing:\n",
        "        raise FileNotFoundError(\"Couldn't find train.csv, val.csv, or test.csv in DATA_DIR\")\n",
        "\n",
        "    dfs = []\n",
        "    for path in existing:\n",
        "        split_name = os.path.splitext(os.path.basename(path))[0]  # \"train\"/\"val\"/\"test\"\n",
        "        raw = pd.read_csv(path)\n",
        "        std = _ensure_required_cols(raw, split_name)\n",
        "        dfs.append(std)\n",
        "\n",
        "    df_all = pd.concat(dfs, ignore_index=True)\n",
        "    print(f\"Loaded {len(df_all)} rows from {len(dfs)} files: {[os.path.basename(p) for p in existing]}\")\n",
        "    return df_all\n",
        "\n",
        "df = load_google_restaurants()\n",
        "print(df.head(), \"\\n\", df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XLWrUESmXN77",
      "metadata": {
        "id": "XLWrUESmXN77"
      },
      "source": [
        "Filter/encode/split and build the graph with train edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fce7adfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fce7adfe",
        "outputId": "caabeef6-e54c-43d7-8e8b-3438905ef0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After filtering: (96003, 15)\n",
            "num_users=36364, num_items=17946\n",
            "HeteroData(\n",
            "  user={ num_nodes=36364 },\n",
            "  item={\n",
            "    num_nodes=17946,\n",
            "    x=[17946, 3],\n",
            "  },\n",
            "  (user, rates, item)={ edge_index=[2, 76769] },\n",
            "  (item, rev_by, user)={ edge_index=[2, 76769] },\n",
            "  (item, similar, item)={ edge_index=[2, 3652] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.utils import to_undirected, coalesce\n",
        "\n",
        "DEVICE = \"cpu\"  # change to \"cuda\" if you have a GPU\n",
        "\n",
        "# ---------- Filtering ----------\n",
        "def filter_min_interactions(df, umin=MIN_USER_INTERACTIONS, imin=MIN_ITEM_INTERACTIONS):\n",
        "    \"\"\"Filter out users/items globally with < umin/imin interactions.\"\"\"\n",
        "    grouped_u = df.groupby(\"user_id\").size()\n",
        "    keep_users = set(grouped_u[grouped_u >= umin].index)\n",
        "    grouped_i = df.groupby(\"item_id\").size()\n",
        "    keep_items = set(grouped_i[grouped_i >= imin].index)\n",
        "    out = df[df.user_id.isin(keep_users) & df.item_id.isin(keep_items)].copy()\n",
        "    return out\n",
        "\n",
        "df_all = filter_min_interactions(df)\n",
        "print(\"After filtering:\", df_all.shape)\n",
        "\n",
        "# ---------- Global encoding ----------\n",
        "u_enc = LabelEncoder().fit(df_all[\"user_id\"])\n",
        "i_enc = LabelEncoder().fit(df_all[\"item_id\"])\n",
        "\n",
        "def encode_df(subdf: pd.DataFrame) -> pd.DataFrame:\n",
        "    subdf = subdf.copy()\n",
        "    # Only keep rows that survived global filtering\n",
        "    subdf = subdf[subdf[\"user_id\"].isin(u_enc.classes_) & subdf[\"item_id\"].isin(i_enc.classes_)]\n",
        "    subdf[\"u\"] = u_enc.transform(subdf[\"user_id\"])\n",
        "    subdf[\"i\"] = i_enc.transform(subdf[\"item_id\"])\n",
        "    return subdf\n",
        "\n",
        "train_df = encode_df(df_all[df_all[\"split\"] == \"train\"])\n",
        "val_df   = encode_df(df_all[df_all[\"split\"] == \"val\"])\n",
        "test_df  = encode_df(df_all[df_all[\"split\"] == \"test\"])\n",
        "\n",
        "num_users = len(u_enc.classes_)\n",
        "num_items = len(i_enc.classes_)\n",
        "print(f\"num_users={num_users}, num_items={num_items}\")\n",
        "\n",
        "# ---------- Build hetero graph (train edges only) ----------\n",
        "data = HeteroData()\n",
        "data[\"user\"].num_nodes = num_users\n",
        "data[\"item\"].num_nodes = num_items\n",
        "\n",
        "# user-item edges from train\n",
        "ui_src = torch.tensor(train_df[\"u\"].values, dtype=torch.long)\n",
        "ui_dst = torch.tensor(train_df[\"i\"].values, dtype=torch.long)\n",
        "edge_index = torch.stack([ui_src, ui_dst], dim=0)\n",
        "data[\"user\", \"rates\", \"item\"].edge_index = edge_index\n",
        "data[\"item\", \"rev_by\", \"user\"].edge_index = edge_index.flip(0)\n",
        "\n",
        "# ---------- Item features (metadata not yet available) ----------\n",
        "# Keep the expected 3-dim feature shape [item_lat, item_lon, price], all zeros.\n",
        "# This matches downstream code expecting a (num_items, 3) tensor.\n",
        "item_x = torch.zeros((num_items, 3), dtype=torch.float)\n",
        "data[\"item\"].x = item_x\n",
        "\n",
        "# ---------- Item-item edges ----------\n",
        "# Co-review edges from train: connect items co-rated by the same user at least twice.\n",
        "co_counts = {}\n",
        "for u, grp in train_df.groupby(\"u\"):\n",
        "    items = grp[\"i\"].tolist()\n",
        "    for a in items:\n",
        "        for b in items:\n",
        "            if a >= b:\n",
        "                continue\n",
        "            co_counts[(a, b)] = co_counts.get((a, b), 0) + 1\n",
        "\n",
        "pairs = [(a, b) for (a, b), c in co_counts.items() if c >= 2]\n",
        "if len(pairs) > 0:\n",
        "    ii_src = [a for a, b in pairs]\n",
        "    ii_dst = [b for a, b in pairs]\n",
        "    ii_edge = torch.tensor([ii_src, ii_dst], dtype=torch.long)\n",
        "    ii_edge = to_undirected(ii_edge)\n",
        "    data[\"item\", \"similar\", \"item\"].edge_index = coalesce(ii_edge, num_nodes=num_items)\n",
        "else:\n",
        "    # If no pairs meet the threshold, create an empty edge_index\n",
        "    data[\"item\", \"similar\", \"item\"].edge_index = torch.empty((2,0), dtype=torch.long)\n",
        "\n",
        "data = data.to(DEVICE)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a8a45a",
      "metadata": {
        "id": "74a8a45a"
      },
      "source": [
        "Sampling, Metrics, and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b76b218f",
      "metadata": {
        "id": "b76b218f"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from typing import Optional, Dict, List, Tuple\n",
        "\n",
        "# ---------- BPR Sampler ----------\n",
        "def bpr_triplet_sampler(train_df: pd.DataFrame, num_items: int,\n",
        "                        radius_km: Optional[float]=None,\n",
        "                        item_latlon: Optional[List[Tuple[float,float]]]=None,\n",
        "                        user_pos_map: Optional[Dict[int,set]]=None,\n",
        "                        user_home_latlon: Optional[Dict[int,Tuple[float,float]]]=None,\n",
        "                        batch_size: int = 2048):\n",
        "    \"\"\"\n",
        "    Yields batches of (u, pos_i, neg_j) for BPR.\n",
        "    Works even if geographic metadata is missing.\n",
        "    \"\"\"\n",
        "    # Build user -> positive item map\n",
        "    if user_pos_map is None:\n",
        "        user_pos_map = {u: set(g[\"i\"].values.tolist()) for u, g in train_df.groupby(\"u\")}\n",
        "    users = list(user_pos_map.keys())\n",
        "\n",
        "    # Precompute safe item_latlon array if not provided\n",
        "    if item_latlon is None or len(item_latlon) != num_items:\n",
        "        item_latlon = [(np.nan, np.nan)] * num_items\n",
        "\n",
        "    while True:\n",
        "        uu, ii, jj = [], [], []\n",
        "        for _ in range(batch_size):\n",
        "            u = random.choice(users)\n",
        "            pos_i = random.choice(list(user_pos_map[u]))\n",
        "\n",
        "            # Negative sampling\n",
        "            if radius_km is not None and item_latlon is not None:\n",
        "                neg_j = None\n",
        "                # Determine user's location center (home or positive item)\n",
        "                center = None\n",
        "                if user_home_latlon and u in user_home_latlon:\n",
        "                    center = user_home_latlon[u]\n",
        "                else:\n",
        "                    lat_i, lon_i = item_latlon[pos_i]\n",
        "                    if not (math.isnan(lat_i) or math.isnan(lon_i)):\n",
        "                        center = (lat_i, lon_i)\n",
        "\n",
        "                # If we have a center, attempt radius-aware sampling\n",
        "                if center:\n",
        "                    latc, lonc = center\n",
        "                    candidates = [k for k in range(num_items) if k not in user_pos_map[u]]\n",
        "                    random.shuffle(candidates)\n",
        "                    for k in candidates:\n",
        "                        latk, lonk = item_latlon[k]\n",
        "                        # skip if no coordinates\n",
        "                        if math.isnan(latk) or math.isnan(lonk):\n",
        "                            continue\n",
        "                        if haversine((latc, lonc), (latk, lonk)) <= radius_km:\n",
        "                            neg_j = k\n",
        "                            break\n",
        "                # Fallback to uniform negative sampling\n",
        "                if neg_j is None:\n",
        "                    while True:\n",
        "                        k = random.randrange(num_items)\n",
        "                        if k not in user_pos_map[u]:\n",
        "                            neg_j = k\n",
        "                            break\n",
        "            else:\n",
        "                # Uniform negative sampling (without geo info for now)\n",
        "                while True:\n",
        "                    k = random.randrange(num_items)\n",
        "                    if k not in user_pos_map[u]:\n",
        "                        neg_j = k\n",
        "                        break\n",
        "\n",
        "            uu.append(u)\n",
        "            ii.append(pos_i)\n",
        "            jj.append(neg_j)\n",
        "\n",
        "        yield (\n",
        "            torch.tensor(uu, device=DEVICE),\n",
        "            torch.tensor(ii, device=DEVICE),\n",
        "            torch.tensor(jj, device=DEVICE)\n",
        "        )\n",
        "\n",
        "# ---------- Ranking Metrics Helper Functions ----------\n",
        "def recall_at_k(ranked_items, ground_truth, k=10):\n",
        "    hits = sum([1 for x in ranked_items[:k] if x in ground_truth])\n",
        "    return hits / float(min(k, len(ground_truth))) if ground_truth else 0.0\n",
        "\n",
        "def ndcg_at_k(ranked_items, ground_truth, k=10):\n",
        "    dcg = sum([1.0 / math.log2(idx + 2) for idx, it in enumerate(ranked_items[:k]) if it in ground_truth])\n",
        "    idcg = sum([1.0 / math.log2(i + 2) for i in range(min(k, len(ground_truth)))])\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def geo_discount(distance_km, R=5.0):\n",
        "    return math.exp(-distance_km / R)\n",
        "\n",
        "def geo_ndcg_at_k(ranked_items, ground_truth, user_loc, item_latlon, k=10, R=5.0):\n",
        "    dcg = 0.0\n",
        "    for idx, it in enumerate(ranked_items[:k], start=1):\n",
        "        if it in ground_truth:\n",
        "            w = 1.0\n",
        "            if user_loc and not any(np.isnan(user_loc)):\n",
        "                latu, lonu = user_loc\n",
        "                lati, loni = item_latlon[it]\n",
        "                if not math.isnan(lati) and not math.isnan(loni):\n",
        "                    d = haversine((latu, lonu), (lati, loni))\n",
        "                    w = geo_discount(d, R=R)\n",
        "            dcg += w / math.log2(idx + 1)\n",
        "    idcg = sum([1.0 / math.log2(i + 2) for i in range(min(k, len(ground_truth)))])\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "def mrr(ranked_items, ground_truth, k=10):\n",
        "    for idx, it in enumerate(ranked_items[:k], start=1):\n",
        "        if it in ground_truth:\n",
        "            return 1.0 / idx\n",
        "    return 0.0\n",
        "\n",
        "def rmse(preds, trues):\n",
        "    return float(np.sqrt(np.mean((np.array(preds) - np.array(trues)) ** 2)))\n",
        "\n",
        "def mae(preds, trues):\n",
        "    return float(np.mean(np.abs(np.array(preds) - np.array(trues))))\n",
        "\n",
        "# ---------- Dataset Helpers ----------\n",
        "# For now, items have dummy coordinates → all NaNs\n",
        "item_latlon = [(float(v[0]), float(v[1])) for v in data[\"item\"].x[:, :2].tolist()]\n",
        "user_home = {}  # optional; keep empty unless you have user locations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51a5158",
      "metadata": {
        "id": "e51a5158"
      },
      "source": [
        "Baseline Model: LightGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "663c9942",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "663c9942",
        "outputId": "58189f40-7a68-4582-b8da-b7e098da9d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGCN] Epoch 01 | Loss = 3.2987\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-161099898.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# ---------- Run Training ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mlightgcn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lightgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-161099898.py\u001b[0m in \u001b[0;36mtrain_lightgcn\u001b[0;34m(epochs, emb_dim, batch_size, lr, reg)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightGCN] Epoch {ep:02d} | Loss = {total/steps:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    950\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdifferentiable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------- Basic LightGCN implementation ----------\n",
        "class LightGCN(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_dim=64, num_layers=4, alpha=None):\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
        "        self.num_layers = num_layers\n",
        "        self.alpha = alpha if alpha is not None else [1/(num_layers+1)]*(num_layers+1)\n",
        "\n",
        "        # Check if the graph has user-item edges\n",
        "        if (\"user\", \"rates\", \"item\") in data.edge_types:\n",
        "            edge = data[\"user\", \"rates\", \"item\"].edge_index\n",
        "            u, i = edge[0], edge[1]\n",
        "            # compute degrees\n",
        "            deg_u = torch.bincount(u, minlength=num_users).float()\n",
        "            deg_i = torch.bincount(i, minlength=num_items).float()\n",
        "        else:\n",
        "            # if no edges (edge_index empty)\n",
        "            u = torch.tensor([], dtype=torch.long)\n",
        "            i = torch.tensor([], dtype=torch.long)\n",
        "            deg_u = torch.ones(num_users)\n",
        "            deg_i = torch.ones(num_items)\n",
        "\n",
        "        self.pairs = (u.to(DEVICE), i.to(DEVICE), deg_u.to(DEVICE), deg_i.to(DEVICE))\n",
        "\n",
        "    def propagate(self, user_x, item_x):\n",
        "        u, i, deg_u, deg_i = self.pairs\n",
        "        all_user = [user_x]\n",
        "        all_item = [item_x]\n",
        "\n",
        "        for _ in range(self.num_layers):\n",
        "            msg_u = torch.zeros_like(user_x)\n",
        "            msg_i = torch.zeros_like(item_x)\n",
        "\n",
        "            if len(u) > 0:  # only if edges exist\n",
        "                msg_u.index_add_(\n",
        "                    0,\n",
        "                    u,\n",
        "                    item_x[i] / torch.sqrt(deg_u[u].unsqueeze(1) * deg_i[i].unsqueeze(1) + 1e-8),\n",
        "                )\n",
        "                msg_i.index_add_(\n",
        "                    0,\n",
        "                    i,\n",
        "                    user_x[u] / torch.sqrt(deg_i[i].unsqueeze(1) * deg_u[u].unsqueeze(1) + 1e-8),\n",
        "                )\n",
        "\n",
        "            user_x, item_x = msg_u, msg_i\n",
        "            all_user.append(user_x)\n",
        "            all_item.append(item_x)\n",
        "\n",
        "        # Weighted layer-wise average\n",
        "        alpha_tensor = torch.tensor(self.alpha, device=user_x.device).view(-1, 1, 1)\n",
        "        user_out = (alpha_tensor * torch.stack(all_user)).sum(0)\n",
        "        item_out = (alpha_tensor * torch.stack(all_item)).sum(0)\n",
        "        return user_out, item_out\n",
        "\n",
        "    def forward(self):\n",
        "        u0 = self.user_emb.weight\n",
        "        i0 = self.item_emb.weight\n",
        "        return self.propagate(u0, i0)\n",
        "\n",
        "    def score(self, users, items, user_emb=None, item_emb=None):\n",
        "        if user_emb is None or item_emb is None:\n",
        "            user_emb, item_emb = self.forward()\n",
        "        return (user_emb[users] * item_emb[items]).sum(dim=1)\n",
        "\n",
        "\n",
        "# ---------- BPR Loss Function ----------\n",
        "def bpr_loss(pos_scores, neg_scores, reg=None, params: list = []):\n",
        "    loss = -F.logsigmoid(pos_scores - neg_scores).mean()\n",
        "    if reg:\n",
        "        loss = loss + reg * sum(p.norm(2).pow(2) for p in params) / len(params)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# ---------- Training Loop ----------\n",
        "def train_lightgcn(epochs=5, emb_dim=64, batch_size=2048, lr=1e-3, reg=1e-4):\n",
        "    model = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "    user_pos = {u: set(g[\"i\"].values.tolist()) for u, g in train_df.groupby(\"u\")}\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        steps = max(1, len(train_df) // batch_size)\n",
        "        for step in range(steps):\n",
        "            u, i, j = next(sampler)\n",
        "            user_emb, item_emb = model()\n",
        "            pos = model.score(u, i, user_emb, item_emb)\n",
        "            neg = model.score(u, j, user_emb, item_emb)\n",
        "            loss = bpr_loss(pos, neg, reg, [model.user_emb.weight, model.item_emb.weight])\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += loss.detach().item()\n",
        "        print(f\"[LightGCN] Epoch {ep:02d} | Loss = {total/steps:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# ---------- Run Training ----------\n",
        "# lightgcn_model = train_lightgcn(epochs=30, emb_dim=128, batch_size=1024, lr=5e-4, reg=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "gAylDBmpbA9E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAylDBmpbA9E",
        "outputId": "a8f902f4-370e-4394-9ec8-2d1f24697d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGCN] Epoch 01 | Loss = 3.2955\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1609.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 1: Recall@5:0.0002 | NDCG@5:0.0002 | MRR@5:0.0003 | Recall@10:0.0006 | NDCG@10:0.0003 | MRR@10:0.0004 | Recall@20:0.0011 | NDCG@20:0.0005 | MRR@20:0.0005\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 02 | Loss = 2.1546\n",
            "[LightGCN] Epoch 03 | Loss = 1.5223\n",
            "[LightGCN] Epoch 04 | Loss = 1.1664\n",
            "[LightGCN] Epoch 05 | Loss = 0.9640\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1705.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 5: Recall@5:0.0012 | NDCG@5:0.0010 | MRR@5:0.0012 | Recall@10:0.0016 | NDCG@10:0.0011 | MRR@10:0.0013 | Recall@20:0.0021 | NDCG@20:0.0013 | MRR@20:0.0014\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 06 | Loss = 0.8483\n",
            "[LightGCN] Epoch 07 | Loss = 0.7820\n",
            "[LightGCN] Epoch 08 | Loss = 0.7440\n",
            "[LightGCN] Epoch 09 | Loss = 0.7222\n",
            "[LightGCN] Epoch 10 | Loss = 0.7096\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1735.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 10: Recall@5:0.0018 | NDCG@5:0.0019 | MRR@5:0.0022 | Recall@10:0.0018 | NDCG@10:0.0019 | MRR@10:0.0022 | Recall@20:0.0025 | NDCG@20:0.0021 | MRR@20:0.0023\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 11 | Loss = 0.7025\n",
            "[LightGCN] Epoch 12 | Loss = 0.6984\n",
            "[LightGCN] Epoch 13 | Loss = 0.6961\n",
            "[LightGCN] Epoch 14 | Loss = 0.6948\n",
            "[LightGCN] Epoch 15 | Loss = 0.6940\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:02<00:00, 1695.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 15: Recall@5:0.0021 | NDCG@5:0.0022 | MRR@5:0.0025 | Recall@10:0.0022 | NDCG@10:0.0022 | MRR@10:0.0026 | Recall@20:0.0025 | NDCG@20:0.0023 | MRR@20:0.0026\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 16 | Loss = 0.6936\n",
            "[LightGCN] Epoch 17 | Loss = 0.6934\n",
            "[LightGCN] Epoch 18 | Loss = 0.6933\n",
            "[LightGCN] Epoch 19 | Loss = 0.6932\n",
            "[LightGCN] Epoch 20 | Loss = 0.6932\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:15<00:00, 229.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 20: Recall@5:0.0019 | NDCG@5:0.0020 | MRR@5:0.0022 | Recall@10:0.0021 | NDCG@10:0.0021 | MRR@10:0.0023 | Recall@20:0.0028 | NDCG@20:0.0023 | MRR@20:0.0024\n",
            "[LightGCN] Epoch 21 | Loss = 0.6931\n",
            "[LightGCN] Epoch 22 | Loss = 0.6931\n",
            "[LightGCN] Epoch 23 | Loss = 0.6931\n",
            "[LightGCN] Epoch 24 | Loss = 0.6931\n",
            "[LightGCN] Epoch 25 | Loss = 0.6931\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:52<00:00, 69.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 25: Recall@5:0.0022 | NDCG@5:0.0022 | MRR@5:0.0025 | Recall@10:0.0025 | NDCG@10:0.0023 | MRR@10:0.0026 | Recall@20:0.0045 | NDCG@20:0.0030 | MRR@20:0.0029\n",
            "New best model (by NDCG@10).\n",
            "[LightGCN] Epoch 26 | Loss = 0.6931\n",
            "[LightGCN] Epoch 27 | Loss = 0.6931\n",
            "[LightGCN] Epoch 28 | Loss = 0.6931\n",
            "[LightGCN] Epoch 29 | Loss = 0.6931\n",
            "[LightGCN] Epoch 30 | Loss = 0.6931\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:53<00:00, 67.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val @Epoch 30: Recall@5:0.0022 | NDCG@5:0.0022 | MRR@5:0.0024 | Recall@10:0.0042 | NDCG@10:0.0029 | MRR@10:0.0029 | Recall@20:0.0046 | NDCG@20:0.0031 | MRR@20:0.0030\n",
            "New best model (by NDCG@10).\n",
            "\n",
            "Loaded best model (by NDCG@10).\n",
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:53<00:00, 68.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on 3642 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3642/3642 [00:52<00:00, 68.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Final Validation:\n",
            "  Recall@5: 0.0022\n",
            "  NDCG@5: 0.0022\n",
            "  MRR@5: 0.0024\n",
            "  Recall@10: 0.0042\n",
            "  NDCG@10: 0.0029\n",
            "  MRR@10: 0.0029\n",
            "  Recall@20: 0.0046\n",
            "  NDCG@20: 0.0031\n",
            "  MRR@20: 0.0030\n",
            "\n",
            "✅ Final Test:\n",
            "  Recall@5: 0.0018\n",
            "  NDCG@5: 0.0021\n",
            "  MRR@5: 0.0029\n",
            "  Recall@10: 0.0029\n",
            "  NDCG@10: 0.0025\n",
            "  MRR@10: 0.0033\n",
            "  Recall@20: 0.0038\n",
            "  NDCG@20: 0.0028\n",
            "  MRR@20: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import math, copy, torch\n",
        "import numpy as np\n",
        "\n",
        "# ---------- Basic LightGCN implementation (+ early stopping) ----------\n",
        "def train_lightgcn_with_eval(\n",
        "    epochs=30,\n",
        "    eval_every=5,\n",
        "    emb_dim=128,\n",
        "    num_layers=3,\n",
        "    batch_size=1024,\n",
        "    lr=5e-4,\n",
        "    reg=1e-4,\n",
        "    k_list=[5, 10, 20],\n",
        "    early_stop_patience=5,      # epochs without improvement on NDCG@10\n",
        "):\n",
        "    model = LightGCN(num_users, num_items, emb_dim=emb_dim, num_layers=num_layers).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "\n",
        "    history = {\"epoch\": [], \"loss\": [], \"val\": []}\n",
        "    best_metric = -1.0\n",
        "    best_state = copy.deepcopy(model.state_dict())\n",
        "    no_improve = 0\n",
        "\n",
        "    steps_per_epoch = max(1, len(train_df) // batch_size)\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "\n",
        "        for _ in range(steps_per_epoch):\n",
        "            u, i, j = next(sampler)\n",
        "            user_emb, item_emb = model()\n",
        "            pos = model.score(u, i, user_emb, item_emb)\n",
        "            neg = model.score(u, j, user_emb, item_emb)\n",
        "            loss = bpr_loss(pos, neg, reg, [model.user_emb.weight, model.item_emb.weight])\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            running += loss.detach().item()   # <- no warning\n",
        "\n",
        "        avg_loss = running / steps_per_epoch\n",
        "        history[\"epoch\"].append(ep)\n",
        "        history[\"loss\"].append(avg_loss)\n",
        "\n",
        "        print(f\"[LightGCN] Epoch {ep:02d} | Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        # ---- periodic validation for early stopping ----\n",
        "        if (ep % eval_every == 0) or (ep == 1) or (ep == epochs):\n",
        "            val_results = evaluate_model(model, train_df, val_df, k_list=k_list)\n",
        "            history[\"val\"].append((ep, val_results))\n",
        "            metric = val_results.get(\"NDCG@10\", 0.0)  # select your key metric\n",
        "\n",
        "            pretty = \" | \".join([f\"{k}:{v:.4f}\" for k, v in val_results.items()])\n",
        "            print(f\"Val @Epoch {ep}: {pretty}\")\n",
        "\n",
        "            # early stopping on the chosen metric\n",
        "            if metric > best_metric + 1e-6:\n",
        "                best_metric = metric\n",
        "                best_state = copy.deepcopy(model.state_dict())\n",
        "                no_improve = 0\n",
        "                print(\"New best model (by NDCG@10).\")\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= early_stop_patience:\n",
        "                    print(f\"Early stopping (no improvement for {early_stop_patience} evals).\")\n",
        "                    break\n",
        "\n",
        "    # load best and report final val/test\n",
        "    model.load_state_dict(best_state)\n",
        "    print(\"\\nLoaded best model (by NDCG@10).\")\n",
        "\n",
        "    val_results  = evaluate_model(model, train_df, val_df,  k_list=k_list)\n",
        "    test_results = evaluate_model(model, train_df, test_df, k_list=k_list)\n",
        "\n",
        "    print(\"\\n✅ Final Validation:\")\n",
        "    for k, v in val_results.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "    print(\"\\n✅ Final Test:\")\n",
        "    for k, v in test_results.items():\n",
        "        print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "    return model, {\"history\": history, \"val\": val_results, \"test\": test_results}\n",
        "\n",
        "# ---- Run it ----\n",
        "lightgcn_model, eval_summary = train_lightgcn_with_eval(\n",
        "    epochs=30,            # increase if still improving\n",
        "    eval_every=5,         # validate every 5 epochs\n",
        "    emb_dim=128,          # try 32/64/128\n",
        "    num_layers=3,         # try 2–4\n",
        "    batch_size=1024,      # adjust for memory\n",
        "    lr=5e-4,\n",
        "    reg=1e-4,\n",
        "    k_list=[5, 10, 20],\n",
        "    early_stop_patience=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fmlusTs7ZkzT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmlusTs7ZkzT",
        "outputId": "2b3ffab3-d0d2-4eae-c449-167d614c3d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on 3628 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3628/3628 [00:01<00:00, 2680.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating on 3642 users...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3642/3642 [00:01<00:00, 2612.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Validation Results:\n",
            "  Recall@5: 0.0021\n",
            "  NDCG@5: 0.0020\n",
            "  MRR@5: 0.0020\n",
            "  Recall@10: 0.0024\n",
            "  NDCG@10: 0.0021\n",
            "  MRR@10: 0.0022\n",
            "  Recall@20: 0.0029\n",
            "  NDCG@20: 0.0023\n",
            "  MRR@20: 0.0023\n",
            "\n",
            "✅ Test Results:\n",
            "  Recall@5: 0.0007\n",
            "  NDCG@5: 0.0008\n",
            "  MRR@5: 0.0012\n",
            "  Recall@10: 0.0007\n",
            "  NDCG@10: 0.0008\n",
            "  MRR@10: 0.0012\n",
            "  Recall@20: 0.0019\n",
            "  NDCG@20: 0.0011\n",
            "  MRR@20: 0.0013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------- Eval helpers ----------\n",
        "def evaluate_model(model, train_df, eval_df, k_list=[5, 10, 20]):\n",
        "    \"\"\"\n",
        "    Evaluate a trained LightGCN model using Recall@K, NDCG@K, and MRR@K.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        user_emb, item_emb = model.forward()\n",
        "\n",
        "    # Build user->train_items map to exclude seen items from ranking\n",
        "    train_user_pos = train_df.groupby(\"u\")[\"i\"].apply(set).to_dict()\n",
        "    eval_user_pos = eval_df.groupby(\"u\")[\"i\"].apply(set).to_dict()\n",
        "\n",
        "    recall_scores = {k: [] for k in k_list}\n",
        "    ndcg_scores = {k: [] for k in k_list}\n",
        "    mrr_scores = {k: [] for k in k_list}\n",
        "\n",
        "    print(f\"Evaluating on {len(eval_user_pos)} users...\")\n",
        "    for u, gt_items in tqdm(eval_user_pos.items()):\n",
        "        if len(gt_items) == 0:\n",
        "            continue\n",
        "\n",
        "        # Compute scores for all items\n",
        "        user_vec = user_emb[u].unsqueeze(0)\n",
        "        scores = torch.matmul(user_vec, item_emb.T).squeeze(0)\n",
        "\n",
        "        # Mask out items the user has already interacted with (training set)\n",
        "        seen_items = train_user_pos.get(u, set())\n",
        "        scores[list(seen_items)] = -1e9\n",
        "\n",
        "        # Get top-K recommendations\n",
        "        ranked_items = torch.topk(scores, k=max(k_list)).indices.cpu().numpy().tolist()\n",
        "\n",
        "        # Compute metrics for each K\n",
        "        for k in k_list:\n",
        "            recall_scores[k].append(recall_at_k(ranked_items, gt_items, k))\n",
        "            ndcg_scores[k].append(ndcg_at_k(ranked_items, gt_items, k))\n",
        "            mrr_scores[k].append(mrr(ranked_items, gt_items, k))\n",
        "\n",
        "    # Aggregate metrics\n",
        "    results = {}\n",
        "    for k in k_list:\n",
        "        results[f\"Recall@{k}\"] = np.mean(recall_scores[k]) if recall_scores[k] else 0.0\n",
        "        results[f\"NDCG@{k}\"] = np.mean(ndcg_scores[k]) if ndcg_scores[k] else 0.0\n",
        "        results[f\"MRR@{k}\"] = np.mean(mrr_scores[k]) if mrr_scores[k] else 0.0\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xdG0w0SMZ40k",
      "metadata": {
        "id": "xdG0w0SMZ40k"
      },
      "outputs": [],
      "source": [
        "# ---------- Evaluate model ----------\n",
        "val_results = evaluate_model(lightgcn_model, train_df, val_df, k_list=[5, 10, 20])\n",
        "test_results = evaluate_model(lightgcn_model, train_df, test_df, k_list=[5, 10, 20])\n",
        "\n",
        "print(\"\\n✅ Validation Results:\")\n",
        "for k, v in val_results.items():\n",
        "    print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Test Results:\")\n",
        "for k, v in test_results.items():\n",
        "    print(f\"  {k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10ae0ee6",
      "metadata": {
        "id": "10ae0ee6"
      },
      "source": [
        "Extension Model 1: LightGCL\n",
        "\n",
        "Elements:\n",
        "1. Contrastive self-supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52be409c",
      "metadata": {
        "id": "52be409c"
      },
      "outputs": [],
      "source": [
        "# Extension Model 1: LightGCL\n",
        "# --------------------------\n",
        "# Fixes vs. the original draft:\n",
        "#  (1) Build the SVD \"global view\" from a *sparse* user–item matrix (no dense .to_dense()).\n",
        "#  (2) Use in-batch InfoNCE (scales to large |U| and |I|) instead of full N x N logits.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def build_svd_view(train_df: pd.DataFrame,\n",
        "                   num_users: int,\n",
        "                   num_items: int,\n",
        "                   rank: int = 64,\n",
        "                   use_ratings: bool = False,\n",
        "                   seed: int = 42):\n",
        "    \"\"\"\n",
        "    Returns SVD (global) embeddings:\n",
        "      Uk  = U_k * sqrt(Sigma_k)   (shape: [num_users, k])\n",
        "      Vk  = V_k * sqrt(Sigma_k)   (shape: [num_items, k])\n",
        "\n",
        "    Uses sparse SVD (SciPy) to avoid materializing a dense user–item matrix.\n",
        "    Falls back to sklearn TruncatedSVD if svds fails to converge.\n",
        "    \"\"\"\n",
        "    import scipy.sparse as sp\n",
        "    from scipy.sparse.linalg import svds\n",
        "\n",
        "    rows = train_df[\"u\"].to_numpy(dtype=np.int64)\n",
        "    cols = train_df[\"i\"].to_numpy(dtype=np.int64)\n",
        "\n",
        "    if use_ratings and \"rating\" in train_df.columns:\n",
        "        vals = train_df[\"rating\"].to_numpy(dtype=np.float32)\n",
        "    else:\n",
        "        vals = np.ones(len(train_df), dtype=np.float32)\n",
        "\n",
        "    M = sp.coo_matrix((vals, (rows, cols)), shape=(num_users, num_items), dtype=np.float32)\n",
        "\n",
        "    k = int(min(rank, min(num_users, num_items) - 1))\n",
        "    if k <= 0:\n",
        "        # Degenerate edge case: return tiny random views.\n",
        "        rng = np.random.default_rng(seed)\n",
        "        Uk = rng.normal(scale=0.01, size=(num_users, 1)).astype(np.float32)\n",
        "        Vk = rng.normal(scale=0.01, size=(num_items, 1)).astype(np.float32)\n",
        "        return torch.from_numpy(Uk).to(DEVICE), torch.from_numpy(Vk).to(DEVICE)\n",
        "\n",
        "    try:\n",
        "        U, S, Vt = svds(M, k=k)  # singular values in ascending order\n",
        "        order = np.argsort(-S)\n",
        "        S = S[order]\n",
        "        U = U[:, order]\n",
        "        Vt = Vt[order, :]\n",
        "\n",
        "        sqrtS = np.sqrt(np.maximum(S, 1e-12)).astype(np.float32)\n",
        "        Uk = (U.astype(np.float32) * sqrtS[None, :])         # U * sqrt(S)\n",
        "        Vk = (Vt.T.astype(np.float32) * sqrtS[None, :])      # V * sqrt(S)\n",
        "    except Exception as e:\n",
        "        # Fallback: TruncatedSVD (more stable on some matrices).\n",
        "        from sklearn.decomposition import TruncatedSVD\n",
        "        svd = TruncatedSVD(n_components=k, random_state=seed)\n",
        "        svd.fit(M)\n",
        "\n",
        "        Vt = svd.components_.astype(np.float32)             # (k, num_items)\n",
        "        S  = svd.singular_values_.astype(np.float32)        # (k,)\n",
        "        sqrtS = np.sqrt(np.maximum(S, 1e-12)).astype(np.float32)\n",
        "\n",
        "        # X = M @ V  == U * Sigma\n",
        "        X = (M @ Vt.T).astype(np.float32)                   # (num_users, k)\n",
        "        Uk = X / sqrtS[None, :]                             # (U*Sigma)/sqrt(Sigma) == U*sqrt(Sigma)\n",
        "        Vk = (Vt.T * sqrtS[None, :])                        # V*sqrt(Sigma)\n",
        "\n",
        "    Uk = torch.from_numpy(Uk).to(torch.float32)\n",
        "    Vk = torch.from_numpy(Vk).to(torch.float32)\n",
        "    return Uk.to(DEVICE), Vk.to(DEVICE)\n",
        "\n",
        "def info_nce_inbatch(z_q: torch.Tensor, z_k: torch.Tensor, temperature: float = 0.2) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    In-batch InfoNCE with aligned positives (diagonal) and other batch elements as negatives.\n",
        "    z_q, z_k: [B, D] with matching rows as positives.\n",
        "    \"\"\"\n",
        "    z_q = F.normalize(z_q, dim=1)\n",
        "    z_k = F.normalize(z_k, dim=1)\n",
        "    logits = (z_q @ z_k.T) / temperature\n",
        "    labels = torch.arange(z_q.size(0), device=z_q.device)\n",
        "    return F.cross_entropy(logits, labels)\n",
        "\n",
        "class LightGCL(nn.Module):\n",
        "    \"\"\"\n",
        "    LightGCN trained with a LightGCL-style global collaborative view (low-rank SVD)\n",
        "    and contrastive alignment between the two embedding spaces.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 base: LightGCN,\n",
        "                 lambda_cl: float = 0.1,\n",
        "                 temperature: float = 0.2,\n",
        "                 svd_rank: int = 64,\n",
        "                 use_ratings: bool = False):\n",
        "        super().__init__()\n",
        "        self.base = base\n",
        "        self.lambda_cl = float(lambda_cl)\n",
        "        self.temperature = float(temperature)\n",
        "\n",
        "        # Precompute global-view embeddings once.\n",
        "        Uk, Vk = build_svd_view(train_df, base.num_users, base.num_items, rank=svd_rank, use_ratings=use_ratings)\n",
        "        self.register_buffer(\"Uk\", Uk)\n",
        "        self.register_buffer(\"Vk\", Vk)\n",
        "\n",
        "    def training_step(self, batch, opt, reg: float = 1e-4) -> float:\n",
        "        u, i, j = batch\n",
        "\n",
        "        # Full embeddings from LightGCN (as in the baseline)\n",
        "        user_emb_all, item_emb_all = self.base()\n",
        "\n",
        "        # BPR supervised term\n",
        "        pos = self.base.score(u, i, user_emb_all, item_emb_all)\n",
        "        neg = self.base.score(u, j, user_emb_all, item_emb_all)\n",
        "        loss_bpr = bpr_loss(pos, neg, reg, [self.base.user_emb.weight, self.base.item_emb.weight])\n",
        "\n",
        "        # Contrastive alignment (in-batch negatives)\n",
        "        u_uniq = torch.unique(u)\n",
        "        it_uniq = torch.unique(torch.cat([i, j], dim=0))\n",
        "\n",
        "        cl_u = info_nce_inbatch(user_emb_all[u_uniq], self.Uk[u_uniq].to(user_emb_all.device), temperature=self.temperature)\n",
        "        cl_i = info_nce_inbatch(item_emb_all[it_uniq], self.Vk[it_uniq].to(item_emb_all.device), temperature=self.temperature)\n",
        "\n",
        "        loss = loss_bpr + self.lambda_cl * (cl_u + cl_i)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        return float(loss.item())\n",
        "\n",
        "def train_lightgcl(epochs: int = 5,\n",
        "                   emb_dim: int = 64,\n",
        "                   svd_rank: int = None,\n",
        "                   batch_size: int = 2048,\n",
        "                   lr: float = 1e-3,\n",
        "                   reg: float = 1e-4,\n",
        "                   lambda_cl: float = 0.1,\n",
        "                   temperature: float = 0.2):\n",
        "    base = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    model = LightGCL(\n",
        "        base,\n",
        "        lambda_cl=lambda_cl,\n",
        "        temperature=temperature,\n",
        "        svd_rank=(svd_rank if svd_rank is not None else emb_dim),\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    opt = torch.optim.Adam(base.parameters(), lr=lr)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        total = 0.0\n",
        "        steps = max(1, len(train_df) // batch_size)\n",
        "        for _ in range(steps):\n",
        "            u, i, j = next(sampler)\n",
        "            total += model.training_step((u, i, j), opt, reg=reg)\n",
        "        print(f\"[LightGCL] epoch {ep} | loss {total / steps:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "lightgcl_model = train_lightgcl(epochs=5, emb_dim=64, lambda_cl=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0d5e11",
      "metadata": {
        "id": "dd0d5e11"
      },
      "source": [
        "Extension Model 2: LightGCL + Geographical Awareness\n",
        "\n",
        "Elements:\n",
        "1. Contrastive self-supervision\n",
        "2. Distance-aware scoring\n",
        "3. Radius-aware negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92e3bc18",
      "metadata": {
        "id": "92e3bc18"
      },
      "outputs": [],
      "source": [
        "# Extension Model 2: LightGCL + Geographical Awareness\n",
        "# ---------------------------------------------------\n",
        "# Adds:\n",
        "#  (1) Distance-aware scoring: dot(u,i) + beta * exp(-d(u,i)/rho)\n",
        "#  (2) Radius-aware negative sampling via bpr_triplet_sampler(..., radius_km=R)\n",
        "#  (3) Optional geo-smoothing regularizer on nearby restaurants (items)\n",
        "\n",
        "import ast\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def _parse_categories(x):\n",
        "    \"\"\"Best-effort parse of categories that may be stored as list, stringified list, or comma-separated string.\"\"\"\n",
        "    if isinstance(x, list):\n",
        "        return [str(t).strip() for t in x if pd.notna(t) and str(t).strip()]\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip()\n",
        "        # stringified Python list\n",
        "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
        "            try:\n",
        "                y = ast.literal_eval(s)\n",
        "                if isinstance(y, (list, tuple)):\n",
        "                    return [str(t).strip() for t in y if pd.notna(t) and str(t).strip()]\n",
        "            except Exception:\n",
        "                pass\n",
        "        # fallback: split\n",
        "        parts = [p.strip() for p in re.split(r\"[;,|]\", s) if p.strip()]\n",
        "        return parts\n",
        "    return [str(x).strip()] if str(x).strip() else []\n",
        "\n",
        "def _safe_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception:\n",
        "        return float(\"nan\")\n",
        "\n",
        "def build_item_latlon(df_any: pd.DataFrame, num_items: int):\n",
        "    \"\"\"\n",
        "    Builds a list of (lat, lon) for every encoded item index i in [0, num_items).\n",
        "    Works even if coordinates are missing: returns (nan, nan) for those items.\n",
        "    \"\"\"\n",
        "    # Ensure an encoded item index exists\n",
        "    if \"i\" not in df_any.columns:\n",
        "        tmp = df_any.copy()\n",
        "        tmp[\"i\"] = i_enc.transform(tmp[\"item_id\"])\n",
        "        df_any = tmp\n",
        "\n",
        "    # Find usable columns (prefer canonical names)\n",
        "    lat_candidates = [\"item_lat\", \"business_lat\", \"business_latitude\", \"latitude\", \"lat\", \"y\"]\n",
        "    lon_candidates = [\"item_lon\", \"business_lon\", \"business_longitude\", \"longitude\", \"lon\", \"lng\", \"x\"]\n",
        "\n",
        "    lat_col = next((c for c in lat_candidates if c in df_any.columns), None)\n",
        "    lon_col = next((c for c in lon_candidates if c in df_any.columns), None)\n",
        "\n",
        "    if lat_col is None or lon_col is None:\n",
        "        return [(math.nan, math.nan) for _ in range(num_items)]\n",
        "\n",
        "    # Coerce to numeric\n",
        "    tmp = df_any[[\"i\", lat_col, lon_col]].copy()\n",
        "    tmp[lat_col] = pd.to_numeric(tmp[lat_col], errors=\"coerce\")\n",
        "    tmp[lon_col] = pd.to_numeric(tmp[lon_col], errors=\"coerce\")\n",
        "\n",
        "    g = tmp.groupby(\"i\")[[lat_col, lon_col]].mean()\n",
        "    arr = np.full((num_items, 2), np.nan, dtype=np.float32)\n",
        "    arr[g.index.to_numpy(dtype=np.int64)] = g.to_numpy(dtype=np.float32)\n",
        "\n",
        "    return [(float(a), float(b)) for a, b in arr]\n",
        "\n",
        "def build_user_home_latlon(train_df: pd.DataFrame, item_latlon):\n",
        "    \"\"\"\n",
        "    Best-effort user \"home\" location:\n",
        "      - If user_lat/user_lon exist and are usable, use their mean.\n",
        "      - Else, estimate from the mean lat/lon of items the user interacted with in train.\n",
        "    \"\"\"\n",
        "    user_home = {}\n",
        "\n",
        "    if \"user_lat\" in train_df.columns and \"user_lon\" in train_df.columns:\n",
        "        tmp = train_df[[\"u\", \"user_lat\", \"user_lon\"]].copy()\n",
        "        tmp[\"user_lat\"] = pd.to_numeric(tmp[\"user_lat\"], errors=\"coerce\")\n",
        "        tmp[\"user_lon\"] = pd.to_numeric(tmp[\"user_lon\"], errors=\"coerce\")\n",
        "        g = tmp.groupby(\"u\")[[\"user_lat\", \"user_lon\"]].mean()\n",
        "        for u, row in g.iterrows():\n",
        "            lat, lon = float(row[\"user_lat\"]), float(row[\"user_lon\"])\n",
        "            if not (math.isnan(lat) or math.isnan(lon)):\n",
        "                user_home[int(u)] = (lat, lon)\n",
        "\n",
        "    # Fill remaining users from interacted item coordinates\n",
        "    for u, g in train_df.groupby(\"u\"):\n",
        "        u = int(u)\n",
        "        if u in user_home:\n",
        "            continue\n",
        "        coords = np.array([item_latlon[int(it)] for it in g[\"i\"].values], dtype=np.float64)\n",
        "        m = ~np.isnan(coords).any(axis=1)\n",
        "        if m.any():\n",
        "            user_home[u] = (float(coords[m, 0].mean()), float(coords[m, 1].mean()))\n",
        "\n",
        "    return user_home\n",
        "\n",
        "def precompute_geo_knn(item_latlon, k: int = 10, rho_r_km: float = 5.0):\n",
        "    \"\"\"\n",
        "    Precompute kNN neighbors for each item using haversine distance (BallTree).\n",
        "    Returns (neighbors, weights), where neighbors[i] is a list of item indices, and weights[i] aligns.\n",
        "    If coords missing, returns (None, None).\n",
        "    \"\"\"\n",
        "    coords = np.array(item_latlon, dtype=np.float64)  # (N,2)\n",
        "    valid = ~np.isnan(coords).any(axis=1)\n",
        "    idx_valid = np.where(valid)[0]\n",
        "    if len(idx_valid) < 2:\n",
        "        return None, None\n",
        "\n",
        "    # BallTree expects radians for haversine metric.\n",
        "    from sklearn.neighbors import BallTree\n",
        "    rad = np.radians(coords[idx_valid])\n",
        "    tree = BallTree(rad, metric=\"haversine\")\n",
        "\n",
        "    qk = min(k + 1, len(idx_valid))\n",
        "    dist_rad, ind = tree.query(rad, k=qk)  # includes self at position 0\n",
        "    dist_km = dist_rad * 6371.0\n",
        "\n",
        "    neighbors = [[] for _ in range(len(coords))]\n",
        "    weights   = [[] for _ in range(len(coords))]\n",
        "\n",
        "    for row, item_idx in enumerate(idx_valid):\n",
        "        neigh_local = ind[row, 1:]                 # drop self\n",
        "        neigh_items = idx_valid[neigh_local]\n",
        "        d = dist_km[row, 1:]\n",
        "        w = np.exp(-d / float(rho_r_km))\n",
        "        neighbors[item_idx] = neigh_items.tolist()\n",
        "        weights[item_idx] = w.astype(np.float32).tolist()\n",
        "\n",
        "    return neighbors, weights\n",
        "\n",
        "class LightGCL_Geo(LightGCL):\n",
        "    def __init__(self,\n",
        "                 base: LightGCN,\n",
        "                 item_latlon,\n",
        "                 user_home_latlon,\n",
        "                 beta: float = 0.2,\n",
        "                 radius_km: float = 5.0,\n",
        "                 rho_km: float = None,\n",
        "                 lambda_cl: float = 0.1,\n",
        "                 temperature: float = 0.2,\n",
        "                 mu_geo_smooth: float = 0.0,\n",
        "                 knn_k: int = 10,\n",
        "                 rho_r_km: float = 5.0):\n",
        "        super().__init__(base,\n",
        "                         lambda_cl=lambda_cl,\n",
        "                         temperature=temperature,\n",
        "                         svd_rank=base.user_emb.embedding_dim)\n",
        "\n",
        "        self.beta = float(beta)\n",
        "        self.radius_km = float(radius_km)\n",
        "        self.rho_km = float(rho_km) if rho_km is not None else float(radius_km)\n",
        "\n",
        "        self.item_latlon = item_latlon\n",
        "        self.user_home = user_home_latlon\n",
        "\n",
        "        # Optional geo-smoothing regularizer\n",
        "        self.mu_geo_smooth = float(mu_geo_smooth)\n",
        "        if self.mu_geo_smooth > 0.0:\n",
        "            self._geo_neighbors, self._geo_weights = precompute_geo_knn(item_latlon, k=knn_k, rho_r_km=rho_r_km)\n",
        "        else:\n",
        "            self._geo_neighbors, self._geo_weights = None, None\n",
        "\n",
        "    def _geo_kernel(self, d_km: float) -> float:\n",
        "        return math.exp(-d_km / self.rho_km)\n",
        "\n",
        "    def _batch_geo_bias(self, users: torch.Tensor, items: torch.Tensor, centers_latlon=None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns exp(-d/rho) for each (u, item) in the batch.\n",
        "        If a user's location is missing, uses centers_latlon[u] if provided (e.g., pos item coords).\n",
        "        \"\"\"\n",
        "        out = []\n",
        "        u_list = users.tolist()\n",
        "        i_list = items.tolist()\n",
        "\n",
        "        if centers_latlon is None:\n",
        "            centers_latlon = [None] * len(u_list)\n",
        "\n",
        "        for idx, (u, it) in enumerate(zip(u_list, i_list)):\n",
        "            center = self.user_home.get(int(u))\n",
        "            if center is None or any(np.isnan(center)):\n",
        "                center = centers_latlon[idx]\n",
        "\n",
        "            lat_i, lon_i = self.item_latlon[int(it)]\n",
        "            if center is None or any(np.isnan(center)) or math.isnan(lat_i) or math.isnan(lon_i):\n",
        "                out.append(0.0)\n",
        "                continue\n",
        "\n",
        "            d = haversine(center, (lat_i, lon_i))  # km\n",
        "            out.append(self._geo_kernel(d))\n",
        "\n",
        "        return torch.tensor(out, device=DEVICE, dtype=torch.float32)\n",
        "\n",
        "    def _geo_smooth_loss(self, item_emb_all: torch.Tensor, items_uniq: torch.Tensor) -> torch.Tensor:\n",
        "        if self._geo_neighbors is None:\n",
        "            return torch.zeros((), device=item_emb_all.device)\n",
        "\n",
        "        loss = 0.0\n",
        "        count = 0\n",
        "        for it in items_uniq.tolist():\n",
        "            neigh = self._geo_neighbors[it]\n",
        "            if not neigh:\n",
        "                continue\n",
        "            w = torch.tensor(self._geo_weights[it], device=item_emb_all.device, dtype=torch.float32).unsqueeze(1)\n",
        "            nbr = torch.tensor(neigh, device=item_emb_all.device, dtype=torch.long)\n",
        "            diff = item_emb_all[it].unsqueeze(0) - item_emb_all[nbr]\n",
        "            loss = loss + (w * diff.pow(2)).sum()\n",
        "            count += len(neigh)\n",
        "\n",
        "        if count == 0:\n",
        "            return torch.zeros((), device=item_emb_all.device)\n",
        "        return loss / count\n",
        "\n",
        "    def training_step(self, batch, opt, reg: float = 1e-4) -> float:\n",
        "        u, i, j = batch\n",
        "\n",
        "        user_emb_all, item_emb_all = self.base()\n",
        "\n",
        "        # Build per-sample centers: user_home if known else pos-item coordinate\n",
        "        centers = []\n",
        "        for it in i.tolist():\n",
        "            latc, lonc = self.item_latlon[int(it)]\n",
        "            centers.append(None if (math.isnan(latc) or math.isnan(lonc)) else (latc, lonc))\n",
        "\n",
        "        pos = self.base.score(u, i, user_emb_all, item_emb_all) + self.beta * self._batch_geo_bias(u, i, centers_latlon=centers)\n",
        "        neg = self.base.score(u, j, user_emb_all, item_emb_all) + self.beta * self._batch_geo_bias(u, j, centers_latlon=centers)\n",
        "\n",
        "        loss_bpr = bpr_loss(pos, neg, reg, [self.base.user_emb.weight, self.base.item_emb.weight])\n",
        "\n",
        "        # Contrastive alignment (in-batch)\n",
        "        u_uniq = torch.unique(u)\n",
        "        it_uniq = torch.unique(torch.cat([i, j], dim=0))\n",
        "\n",
        "        cl_u = info_nce_inbatch(user_emb_all[u_uniq], self.Uk[u_uniq].to(user_emb_all.device), temperature=self.temperature)\n",
        "        cl_i = info_nce_inbatch(item_emb_all[it_uniq], self.Vk[it_uniq].to(item_emb_all.device), temperature=self.temperature)\n",
        "\n",
        "        loss = loss_bpr + self.lambda_cl * (cl_u + cl_i)\n",
        "\n",
        "        # Geo smoothing (optional)\n",
        "        if self.mu_geo_smooth > 0.0:\n",
        "            loss = loss + self.mu_geo_smooth * self._geo_smooth_loss(item_emb_all, it_uniq)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        return float(loss.item())\n",
        "\n",
        "def train_lightgcl_geo(epochs: int = 5,\n",
        "                       emb_dim: int = 64,\n",
        "                       batch_size: int = 2048,\n",
        "                       lr: float = 1e-3,\n",
        "                       reg: float = 1e-4,\n",
        "                       lambda_cl: float = 0.1,\n",
        "                       temperature: float = 0.2,\n",
        "                       beta: float = 0.3,\n",
        "                       R: float = 5.0,\n",
        "                       mu_geo_smooth: float = 0.0):\n",
        "    # Build coordinate tables (robust to missing metadata)\n",
        "    df_enc_all = encode_df(df_all)  # adds u/i columns\n",
        "    item_latlon = build_item_latlon(df_enc_all, num_items)\n",
        "    user_home = build_user_home_latlon(train_df, item_latlon)\n",
        "\n",
        "    base = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "    model = LightGCL_Geo(\n",
        "        base=base,\n",
        "        item_latlon=item_latlon,\n",
        "        user_home_latlon=user_home,\n",
        "        beta=beta,\n",
        "        radius_km=R,\n",
        "        rho_km=R,\n",
        "        lambda_cl=lambda_cl,\n",
        "        temperature=temperature,\n",
        "        mu_geo_smooth=mu_geo_smooth,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    opt = torch.optim.Adam(base.parameters(), lr=lr)\n",
        "\n",
        "    sampler = bpr_triplet_sampler(\n",
        "        train_df,\n",
        "        num_items,\n",
        "        radius_km=R,\n",
        "        item_latlon=item_latlon,\n",
        "        user_pos_map=None,           # let sampler build it from train_df\n",
        "        user_home_latlon=user_home,  # enables radius-aware negatives when possible\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        total = 0.0\n",
        "        steps = max(1, len(train_df) // batch_size)\n",
        "        for _ in range(steps):\n",
        "            u, i, j = next(sampler)\n",
        "            total += model.training_step((u, i, j), opt, reg=reg)\n",
        "        print(f\"[LightGCL+Geo] epoch {ep} | loss {total / steps:.4f}\")\n",
        "\n",
        "    # expose for evaluation helpers\n",
        "    return model, item_latlon, user_home\n",
        "\n",
        "lightgcl_geo_model, item_latlon, user_home = train_lightgcl_geo(\n",
        "    epochs=5, emb_dim=64, beta=0.3, R=5.0, lambda_cl=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94239d6d",
      "metadata": {
        "id": "94239d6d"
      },
      "source": [
        "Comparative Model 1: PinSage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28af8794",
      "metadata": {
        "id": "28af8794"
      },
      "outputs": [],
      "source": [
        "# Comparative Model 1: PinSage (practical PyG approximation)\n",
        "# ----------------------------------------------------------\n",
        "# A full PinSage implementation requires random-walk neighbor sampling + importance pooling.\n",
        "# For this project notebook, we implement a *drop-in runnable* approximation:\n",
        "#   - Build an item-item graph from co-review edges (already in `data[\"item\",\"similar\",\"item\"]`)\n",
        "#   - Learn item embeddings with GraphSAGE over that item graph\n",
        "#   - Learn user embeddings directly (trainable table)\n",
        "#   - Train with the same BPR triplets as the baseline\n",
        "#\n",
        "# This preserves the \"item-graph recommender\" spirit and runs on the current dataset format.\n",
        "\n",
        "class PinSageRecommender(nn.Module):\n",
        "    def __init__(self, num_users: int, num_items: int, hidden_dim: int = 64, num_layers: int = 2, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.user_emb = nn.Embedding(num_users, hidden_dim)\n",
        "        self.item_emb = nn.Embedding(num_items, hidden_dim)\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.1)\n",
        "\n",
        "        self.convs = nn.ModuleList([SAGEConv(hidden_dim, hidden_dim) for _ in range(num_layers)])\n",
        "        self.dropout = float(dropout)\n",
        "\n",
        "    def forward(self, item_edge_index: torch.Tensor):\n",
        "        # Item graph message passing\n",
        "        x = self.item_emb.weight\n",
        "        if item_edge_index is not None and item_edge_index.numel() > 0:\n",
        "            for conv in self.convs:\n",
        "                x = conv(x, item_edge_index)\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return self.user_emb.weight, x\n",
        "\n",
        "    def score(self, users, items, user_emb=None, item_emb=None, item_edge_index=None):\n",
        "        if user_emb is None or item_emb is None:\n",
        "            user_emb, item_emb = self.forward(item_edge_index)\n",
        "        return (user_emb[users] * item_emb[items]).sum(dim=1)\n",
        "\n",
        "def train_pinsage(epochs: int = 5,\n",
        "                  hidden_dim: int = 64,\n",
        "                  num_layers: int = 2,\n",
        "                  batch_size: int = 2048,\n",
        "                  lr: float = 1e-3,\n",
        "                  reg: float = 1e-4):\n",
        "    model = PinSageRecommender(num_users, num_items, hidden_dim=hidden_dim, num_layers=num_layers).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    ii = data[\"item\", \"similar\", \"item\"].edge_index.to(DEVICE)\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        steps = max(1, len(train_df) // batch_size)\n",
        "        for _ in range(steps):\n",
        "            u, i, j = next(sampler)\n",
        "            ue, ie = model(ii)\n",
        "            pos = (ue[u] * ie[i]).sum(1)\n",
        "            neg = (ue[u] * ie[j]).sum(1)\n",
        "            loss = bpr_loss(pos, neg, reg, [model.user_emb.weight, model.item_emb.weight])\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += float(loss.item())\n",
        "        print(f\"[PinSage(GraphSAGE)] epoch {ep} | loss {total / steps:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "pinsage_model = train_pinsage(epochs=5, hidden_dim=64, num_layers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd05290f",
      "metadata": {
        "id": "fd05290f"
      },
      "source": [
        "Comparative Model 2: LightGCN + HGT\n",
        "\n",
        "Elements:\n",
        "1. Base Model LightGCN\n",
        "2. HGT item representation layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2e9d0f",
      "metadata": {
        "id": "2d2e9d0f"
      },
      "outputs": [],
      "source": [
        "# Comparative Model 2: LightGCN + HGT (heterogeneous metadata)\n",
        "# ------------------------------------------------------------\n",
        "# Fixes vs. the original draft:\n",
        "#  (1) Uses the encoded item index `i` (not the raw `df` without encoding).\n",
        "#  (2) Robustly parses categories/price and builds a HeteroData graph with reverse edges.\n",
        "#  (3) Uses the PyG HGTConv API (metadata-based constructor).\n",
        "\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def _parse_price(x):\n",
        "    if pd.isna(x):\n",
        "        return 0\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip()\n",
        "        # \"$$\", \"$$$\" style\n",
        "        if s and all(ch == \"$\" for ch in s):\n",
        "            return len(s)\n",
        "        try:\n",
        "            return int(float(s))\n",
        "        except Exception:\n",
        "            return 0\n",
        "    try:\n",
        "        return int(x)\n",
        "    except Exception:\n",
        "        return 0\n",
        "\n",
        "def _parse_cats(x):\n",
        "    if isinstance(x, list):\n",
        "        return [str(t).strip() for t in x if pd.notna(t) and str(t).strip()]\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        s = x.strip()\n",
        "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
        "            try:\n",
        "                y = ast.literal_eval(s)\n",
        "                if isinstance(y, (list, tuple)):\n",
        "                    return [str(t).strip() for t in y if pd.notna(t) and str(t).strip()]\n",
        "            except Exception:\n",
        "                pass\n",
        "        return [p.strip() for p in re.split(r\"[;,|]\", s) if p.strip()]\n",
        "    return [str(x).strip()] if str(x).strip() else []\n",
        "\n",
        "# Build an encoded \"all interactions\" DF with i (item index)\n",
        "df_enc_all = encode_df(df_all)  # contains u/i + original columns\n",
        "\n",
        "# Collect per-item metadata (categories / price)\n",
        "item_meta = {}\n",
        "for it, g in df_enc_all.groupby(\"i\"):\n",
        "    it = int(it)\n",
        "    # categories\n",
        "    cats = []\n",
        "    if \"categories\" in g.columns:\n",
        "        for v in g[\"categories\"].tolist():\n",
        "            cats = _parse_cats(v)\n",
        "            if len(cats) > 0:\n",
        "                break\n",
        "    # price\n",
        "    p = 0\n",
        "    if \"price\" in g.columns:\n",
        "        for v in g[\"price\"].tolist():\n",
        "            p = _parse_price(v)\n",
        "            if p != 0:\n",
        "                break\n",
        "    item_meta[it] = {\"cats\": cats, \"price\": p}\n",
        "\n",
        "# Category vocabulary\n",
        "all_cats = []\n",
        "for it in range(num_items):\n",
        "    all_cats += item_meta.get(it, {}).get(\"cats\", [])\n",
        "if len(all_cats) == 0:\n",
        "    all_cats = [\"unknown\"]\n",
        "\n",
        "cat_encoder = LabelEncoder()\n",
        "cat_encoder.fit(sorted(set(all_cats)))\n",
        "num_cats = len(cat_encoder.classes_)\n",
        "\n",
        "# Price vocabulary (ensure 0 exists)\n",
        "all_prices = [_parse_price(item_meta.get(i, {}).get(\"price\", 0)) for i in range(num_items)]\n",
        "price_levels = sorted(set(all_prices + [0]))\n",
        "price_to_idx = {p: idx for idx, p in enumerate(price_levels)}\n",
        "num_prices = len(price_levels)\n",
        "\n",
        "# Build hetero metadata graph\n",
        "meta = HeteroData()\n",
        "meta[\"item\"].num_nodes = num_items\n",
        "meta[\"cat\"].num_nodes = num_cats\n",
        "meta[\"price\"].num_nodes = num_prices\n",
        "\n",
        "# item <-> cat edges\n",
        "src_item, dst_cat = [], []\n",
        "for it in range(num_items):\n",
        "    cats = item_meta.get(it, {}).get(\"cats\", [])\n",
        "    if not cats:\n",
        "        cats = [cat_encoder.classes_[0]]\n",
        "    for c in cats[:3]:\n",
        "        src_item.append(it)\n",
        "        dst_cat.append(int(cat_encoder.transform([c])[0]))\n",
        "\n",
        "edge_ic = torch.tensor([src_item, dst_cat], dtype=torch.long)\n",
        "meta[\"item\", \"has_cat\", \"cat\"].edge_index = edge_ic\n",
        "meta[\"cat\", \"rev_has_cat\", \"item\"].edge_index = edge_ic.flip(0)\n",
        "\n",
        "# item <-> price edges\n",
        "src_item, dst_price = [], []\n",
        "for it in range(num_items):\n",
        "    p = _parse_price(item_meta.get(it, {}).get(\"price\", 0))\n",
        "    src_item.append(it)\n",
        "    dst_price.append(int(price_to_idx.get(p, 0)))\n",
        "\n",
        "edge_ip = torch.tensor([src_item, dst_price], dtype=torch.long)\n",
        "meta[\"item\", \"has_price\", \"price\"].edge_index = edge_ip\n",
        "meta[\"price\", \"rev_has_price\", \"item\"].edge_index = edge_ip.flip(0)\n",
        "\n",
        "meta = meta.to(DEVICE)\n",
        "\n",
        "class HGTItemEncoder(nn.Module):\n",
        "    def __init__(self, hidden: int = 64, heads: int = 2, layers: int = 2, metadata=None):\n",
        "        super().__init__()\n",
        "        self.hidden = hidden\n",
        "        self.emb = nn.ModuleDict({\n",
        "            \"item\": nn.Embedding(num_items, hidden),\n",
        "            \"cat\": nn.Embedding(num_cats, hidden),\n",
        "            \"price\": nn.Embedding(num_prices, hidden),\n",
        "        })\n",
        "        for k in self.emb:\n",
        "            nn.init.xavier_uniform_(self.emb[k].weight)\n",
        "\n",
        "        if metadata is None:\n",
        "            metadata = meta.metadata()\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            HGTConv(hidden, hidden, metadata, heads=heads)\n",
        "            for _ in range(layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, meta_data: HeteroData):\n",
        "        x_dict = {k: self.emb[k].weight for k in meta_data.node_types}\n",
        "        for conv in self.convs:\n",
        "            x_dict = conv(x_dict, meta_data.edge_index_dict)\n",
        "            x_dict = {k: F.relu(v) for k, v in x_dict.items()}\n",
        "        return x_dict[\"item\"]\n",
        "\n",
        "class LightGCN_HGT(nn.Module):\n",
        "    def __init__(self, emb_dim: int = 64, hgt_hidden: int = 64, heads: int = 2, layers: int = 2):\n",
        "        super().__init__()\n",
        "        self.lgcn = LightGCN(num_users, num_items, emb_dim=emb_dim).to(DEVICE)\n",
        "        self.hgt = HGTItemEncoder(hidden=hgt_hidden, heads=heads, layers=layers, metadata=meta.metadata()).to(DEVICE)\n",
        "        self.fuse = nn.Linear(emb_dim + hgt_hidden, emb_dim)\n",
        "\n",
        "    def fused_item_emb(self):\n",
        "        ue, ie = self.lgcn()\n",
        "        hgt_item = self.hgt(meta)\n",
        "        fused = self.fuse(torch.cat([ie, hgt_item], dim=1))\n",
        "        return ue, fused\n",
        "\n",
        "def train_lightgcn_hgt(epochs: int = 5,\n",
        "                       emb_dim: int = 64,\n",
        "                       hgt_hidden: int = 64,\n",
        "                       batch_size: int = 2048,\n",
        "                       lr: float = 1e-3,\n",
        "                       reg: float = 1e-4):\n",
        "    model = LightGCN_HGT(emb_dim=emb_dim, hgt_hidden=hgt_hidden).to(DEVICE)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    sampler = bpr_triplet_sampler(train_df, num_items, batch_size=batch_size)\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total = 0.0\n",
        "        steps = max(1, len(train_df) // batch_size)\n",
        "        for _ in range(steps):\n",
        "            u, i, j = next(sampler)\n",
        "            ue, fused = model.fused_item_emb()\n",
        "            pos = (ue[u] * fused[i]).sum(1)\n",
        "            neg = (ue[u] * fused[j]).sum(1)\n",
        "            loss = bpr_loss(pos, neg, reg, list(model.parameters()))\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total += float(loss.item())\n",
        "        print(f\"[LightGCN+HGT] epoch {ep} | loss {total / steps:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "lghgt_model = train_lightgcn_hgt(epochs=5, emb_dim=64, hgt_hidden=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6266ac98",
      "metadata": {
        "id": "6266ac98"
      },
      "source": [
        "Evaluation Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300782ec",
      "metadata": {
        "id": "300782ec"
      },
      "outputs": [],
      "source": [
        "# Evaluation Helpers\n",
        "# ------------------\n",
        "# Computes ranking metrics (Recall/NDCG/GeoNDCG/MRR) for each trained model.\n",
        "# Fixes:\n",
        "#  - Evaluates the *actual* model objects (not just their base components).\n",
        "#  - Handles each model's embedding/scoring interface consistently.\n",
        "\n",
        "def _vectorized_haversine_km(lat1, lon1, lat2, lon2):\n",
        "    \"\"\"\n",
        "    Vectorized haversine distance from a single point (lat1, lon1) to arrays lat2/lon2.\n",
        "    Inputs are degrees, output is km.\n",
        "    \"\"\"\n",
        "    lat1 = np.radians(lat1); lon1 = np.radians(lon1)\n",
        "    lat2 = np.radians(lat2); lon2 = np.radians(lon2)\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
        "    c = 2.0 * np.arcsin(np.minimum(1.0, np.sqrt(a)))\n",
        "    return 6371.0 * c\n",
        "\n",
        "def full_ranking_scores(model, model_name: str, K_list=(5, 10), geo_R: float = 5.0):\n",
        "    K = int(max(K_list))\n",
        "\n",
        "    # train positives (masking) + heldout ground truth\n",
        "    train_pos = {u: set(g[\"i\"].values.tolist()) for u, g in train_df.groupby(\"u\")}\n",
        "    gt_val = {u: set(g[\"i\"].values.tolist()) for u, g in val_df.groupby(\"u\")}\n",
        "    gt_test = {u: set(g[\"i\"].values.tolist()) for u, g in test_df.groupby(\"u\")}\n",
        "\n",
        "    # Precompute item coords arrays for fast geo scoring (if available)\n",
        "    if \"item_latlon\" in globals() and item_latlon is not None:\n",
        "        _item_lat = np.array([x[0] for x in item_latlon], dtype=np.float64)\n",
        "        _item_lon = np.array([x[1] for x in item_latlon], dtype=np.float64)\n",
        "        _item_has = ~np.isnan(_item_lat) & ~np.isnan(_item_lon)\n",
        "    else:\n",
        "        _item_lat = _item_lon = None\n",
        "        _item_has = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get embeddings / scoring behavior per model\n",
        "        if isinstance(model, LightGCL_Geo):\n",
        "            ue, ie = model.base()\n",
        "            beta = model.beta\n",
        "            rho = model.rho_km\n",
        "            uhome = model.user_home\n",
        "\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "\n",
        "                # geo bonus\n",
        "                loc = uhome.get(int(u))\n",
        "                if loc is not None and _item_lat is not None and not any(np.isnan(loc)):\n",
        "                    latu, lonu = loc\n",
        "                    d = np.full(num_items, np.inf, dtype=np.float64)\n",
        "                    d[_item_has] = _vectorized_haversine_km(latu, lonu, _item_lat[_item_has], _item_lon[_item_has])\n",
        "                    geo = np.exp(-d / float(rho)).astype(np.float32)\n",
        "                    geo[~_item_has] = 0.0\n",
        "                    s = s + beta * torch.tensor(geo, device=DEVICE)\n",
        "\n",
        "                for it in train_pos.get(u, []):\n",
        "                    s[it] = -1e9\n",
        "                return s\n",
        "\n",
        "        elif isinstance(model, LightGCL):\n",
        "            ue, ie = model.base()\n",
        "\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u, []):\n",
        "                    s[it] = -1e9\n",
        "                return s\n",
        "\n",
        "        elif isinstance(model, LightGCN):\n",
        "            ue, ie = model()\n",
        "\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u, []):\n",
        "                    s[it] = -1e9\n",
        "                return s\n",
        "\n",
        "        elif isinstance(model, PinSageRecommender):\n",
        "            ii = data[\"item\", \"similar\", \"item\"].edge_index.to(DEVICE)\n",
        "            ue, ie = model(ii)\n",
        "\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u, []):\n",
        "                    s[it] = -1e9\n",
        "                return s\n",
        "\n",
        "        elif isinstance(model, LightGCN_HGT):\n",
        "            ue, ie = model.fused_item_emb()\n",
        "\n",
        "            def score_u(u):\n",
        "                s = (ue[u].unsqueeze(0) * ie).sum(1)\n",
        "                for it in train_pos.get(u, []):\n",
        "                    s[it] = -1e9\n",
        "                return s\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type for evaluation: {type(model)}\")\n",
        "\n",
        "        def evaluate(gt_dict):\n",
        "            recs, ndcgs, geondcgs, mrrs = [], [], [], []\n",
        "            for u, truth in gt_dict.items():\n",
        "                if not truth:\n",
        "                    continue\n",
        "                scores = score_u(u)\n",
        "                topk = torch.topk(scores, k=K).indices.tolist()\n",
        "                recs.append(recall_at_k(topk, truth, k=K))\n",
        "                ndcgs.append(ndcg_at_k(topk, truth, k=K))\n",
        "                # geo-aware NDCG (if coords exist)\n",
        "                u_loc = None\n",
        "                if isinstance(model, LightGCL_Geo):\n",
        "                    u_loc = model.user_home.get(int(u))\n",
        "                elif \"user_home\" in globals():\n",
        "                    u_loc = user_home.get(int(u))\n",
        "                geondcgs.append(geo_ndcg_at_k(topk, truth, u_loc, item_latlon, k=K, R=geo_R) if (\"item_latlon\" in globals() and item_latlon is not None) else ndcg_at_k(topk, truth, k=K))\n",
        "                mrrs.append(mrr(topk, truth, k=K))\n",
        "\n",
        "            return (\n",
        "                float(np.mean(recs)) if recs else 0.0,\n",
        "                float(np.mean(ndcgs)) if ndcgs else 0.0,\n",
        "                float(np.mean(geondcgs)) if geondcgs else 0.0,\n",
        "                float(np.mean(mrrs)) if mrrs else 0.0,\n",
        "            )\n",
        "\n",
        "        val_scores = evaluate(gt_val)\n",
        "        test_scores = evaluate(gt_test)\n",
        "\n",
        "    print(f\"[{model_name}] Val  Recall@{K}:{val_scores[0]:.4f}  NDCG@{K}:{val_scores[1]:.4f}  GeoNDCG@{K}:{val_scores[2]:.4f}  MRR@{K}:{val_scores[3]:.4f}\")\n",
        "    print(f\"[{model_name}] Test Recall@{K}:{test_scores[0]:.4f}  NDCG@{K}:{test_scores[1]:.4f}  GeoNDCG@{K}:{test_scores[2]:.4f}  MRR@{K}:{test_scores[3]:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"model\": model_name,\n",
        "        \"val_recall\": val_scores[0],\n",
        "        \"val_ndcg\": val_scores[1],\n",
        "        \"val_geondcg\": val_scores[2],\n",
        "        \"val_mrr\": val_scores[3],\n",
        "        \"test_recall\": test_scores[0],\n",
        "        \"test_ndcg\": test_scores[1],\n",
        "        \"test_geondcg\": test_scores[2],\n",
        "        \"test_mrr\": test_scores[3],\n",
        "    }\n",
        "\n",
        "results = []\n",
        "results.append(full_ranking_scores(lightgcn_model, \"LightGCN\"))\n",
        "results.append(full_ranking_scores(lightgcl_model, \"LightGCL\"))\n",
        "results.append(full_ranking_scores(lightgcl_geo_model, \"LightGCL+Geo\", geo_R=5.0))\n",
        "results.append(full_ranking_scores(pinsage_model, \"PinSage (item-item GraphSAGE)\"))\n",
        "results.append(full_ranking_scores(lghgt_model, \"LightGCN+HGT\"))\n",
        "\n",
        "pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cecca63",
      "metadata": {
        "id": "8cecca63"
      },
      "source": [
        "Rating Metrics (RMSE/MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8838d9a2",
      "metadata": {
        "id": "8838d9a2"
      },
      "outputs": [],
      "source": [
        "# Rating Metrics (RMSE/MAE)\n",
        "# -------------------------\n",
        "# Note: Models are trained with implicit-feedback BPR, so raw dot-product scores are *not*\n",
        "# calibrated to the 1–5 rating scale. We still compute RMSE/MAE on these scores as a\n",
        "# relative comparison (lower is better).\n",
        "\n",
        "def pointwise_eval(model, which: str = \"val\"):\n",
        "    df_eval = val_df if which == \"val\" else test_df\n",
        "    preds, trues = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if isinstance(model, LightGCL_Geo):\n",
        "            ue, ie = model.base()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                u = int(r.u); it = int(r.i)\n",
        "                s = float((ue[u] * ie[it]).sum().item())\n",
        "                # geo bonus (if possible)\n",
        "                loc = model.user_home.get(u)\n",
        "                lat_i, lon_i = model.item_latlon[it]\n",
        "                if loc is not None and not any(np.isnan(loc)) and not (math.isnan(lat_i) or math.isnan(lon_i)):\n",
        "                    s += float(model.beta * math.exp(-haversine(loc, (lat_i, lon_i)) / model.rho_km))\n",
        "                preds.append(s)\n",
        "                trues.append(float(r.rating))\n",
        "\n",
        "        elif isinstance(model, LightGCL):\n",
        "            ue, ie = model.base()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                preds.append(float((ue[int(r.u)] * ie[int(r.i)]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "\n",
        "        elif isinstance(model, LightGCN):\n",
        "            ue, ie = model()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                preds.append(float((ue[int(r.u)] * ie[int(r.i)]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "\n",
        "        elif isinstance(model, PinSageRecommender):\n",
        "            ii = data[\"item\", \"similar\", \"item\"].edge_index.to(DEVICE)\n",
        "            ue, ie = model(ii)\n",
        "            for _, r in df_eval.iterrows():\n",
        "                preds.append(float((ue[int(r.u)] * ie[int(r.i)]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "\n",
        "        elif isinstance(model, LightGCN_HGT):\n",
        "            ue, ie = model.fused_item_emb()\n",
        "            for _, r in df_eval.iterrows():\n",
        "                preds.append(float((ue[int(r.u)] * ie[int(r.i)]).sum().item()))\n",
        "                trues.append(float(r.rating))\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {type(model)}\")\n",
        "\n",
        "    return {\"rmse\": rmse(preds, trues), \"mae\": mae(preds, trues), \"n\": len(trues)}\n",
        "\n",
        "for name, mdl in [\n",
        "    (\"LightGCN\", lightgcn_model),\n",
        "    (\"LightGCL\", lightgcl_model),\n",
        "    (\"LightGCL+Geo\", lightgcl_geo_model),\n",
        "    (\"PinSage\", pinsage_model),\n",
        "    (\"LightGCN+HGT\", lghgt_model),\n",
        "]:\n",
        "    out = pointwise_eval(mdl, \"test\")\n",
        "    print(f\"[{name}] RMSE: {out['rmse']:.4f} | MAE: {out['mae']:.4f} | n={out['n']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d1b4ae7",
      "metadata": {
        "id": "3d1b4ae7"
      },
      "source": [
        "Vistualization: Comparison Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8bc962c",
      "metadata": {
        "id": "b8bc962c"
      },
      "outputs": [],
      "source": [
        "# Visualization: Comparison Table\n",
        "# -------------------------------\n",
        "summary = pd.DataFrame(results).copy()\n",
        "\n",
        "models_in_order = [lightgcn_model, lightgcl_model, lightgcl_geo_model, pinsage_model, lghgt_model]\n",
        "summary[\"rmse\"] = [pointwise_eval(m, \"test\")[\"rmse\"] for m in models_in_order]\n",
        "summary[\"mae\"]  = [pointwise_eval(m, \"test\")[\"mae\"]  for m in models_in_order]\n",
        "\n",
        "summary = summary[[\"model\", \"test_recall\", \"test_ndcg\", \"test_geondcg\", \"test_mrr\", \"rmse\", \"mae\"]]\n",
        "summary.sort_values(\"test_ndcg\", ascending=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
